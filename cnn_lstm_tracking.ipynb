{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e75c66",
   "metadata": {},
   "source": [
    "# 1. Setup & Imports\n",
    "This segment installs any required dependencies and imports the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c30055ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries if not already installed\n",
    "# !pip install tensorflow numpy opencv-python-headless matplotlib scikit-learn\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24d9744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "DATASET_PATH = \"dataset/personpath22/raw_data/pathtrack/pathtrack_release/\"\n",
    "TRAIN_PATH = os.path.join(DATASET_PATH, \"train\")\n",
    "TEST_PATH = os.path.join(DATASET_PATH, \"test\")\n",
    "TRAIN_HDF5_FILE = os.path.join(\"dataset\", \"personpath22\", \"pathtrack_matched\", \"train\", \"merged_data.h5\")\n",
    "TEST_HDF5_FILE = os.path.join(\"dataset\", \"personpath22\", \"pathtrack_matched\", \"test\", \"merged_data.h5\")\n",
    "TRAIN_INDIVIDUAL_H5_DIR = os.path.join(\"dataset\", \"personpath22\", \"pathtrack_matched\", \"train\")\n",
    "TEST_INDIVIDUAL_H5_DIR = os.path.join(\"dataset\", \"personpath22\", \"pathtrack_matched\", \"test\")\n",
    "FEATURES_DIR = os.path.join(\"dataset\", \"personpath22\", \"features\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(TRAIN_INDIVIDUAL_H5_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_INDIVIDUAL_H5_DIR, exist_ok=True)\n",
    "os.makedirs(FEATURES_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4150e6bd",
   "metadata": {},
   "source": [
    "# 2. Path and Data Loading Configuration\n",
    "This part helps you configure paths to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b602aa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping '-bnYpCiwV2Q_301_308' as it already exists.\n",
      "Skipping '-cKE8pyfcZc_38_46' as it already exists.\n",
      "Skipping '-DGzHCfmv5k_23_30' as it already exists.\n",
      "Skipping '-DGzHCfmv5k_92_97' as it already exists.\n",
      "Skipping '-fe32cvcpDI_378_388' as it already exists.\n",
      "Skipping '-kX6T3DkExg_85_94' as it already exists.\n",
      "Skipping '-LRxcWBl7P8_112_124' as it already exists.\n",
      "Skipping '0-ENiq-1R5M_226_240' as it already exists.\n",
      "Skipping '00np___nE5s_314_322' as it already exists.\n",
      "Skipping '00np___nE5s_394_404' as it already exists.\n",
      "Skipping '00np___nE5s_465_471' as it already exists.\n",
      "Skipping '00np___nE5s_481_506' as it already exists.\n",
      "Skipping '03tAll3Rnb8_145_160' as it already exists.\n",
      "Skipping '08u_l3VMtFM_204_243' as it already exists.\n",
      "Skipping '08u_l3VMtFM_848_861' as it already exists.\n",
      "Skipping '08u_l3VMtFM_93_116' as it already exists.\n",
      "Skipping '08xgGFk5fds_739_749' as it already exists.\n",
      "Skipping '08xgGFk5fds_762_768' as it already exists.\n",
      "Skipping '08xgGFk5fds_905_915' as it already exists.\n",
      "Skipping '0BHL32Bw70E_221_227' as it already exists.\n",
      "Skipping '0BHL32Bw70E_95_104' as it already exists.\n",
      "Skipping '0dnkuv1CF9M_211_238' as it already exists.\n",
      "Skipping '0fTU-1BX8xk_71_109' as it already exists.\n",
      "Skipping '0TCfRnb1AiM_191_206' as it already exists.\n",
      "Skipping '0TCfRnb1AiM_36_46' as it already exists.\n",
      "Skipping '0TCfRnb1AiM_99_110' as it already exists.\n",
      "Skipping '0TUKi6_pv_E_356_367' as it already exists.\n",
      "Skipping '0Xtp77A4zF4_344_448' as it already exists.\n",
      "Skipping '0Xtp77A4zF4_449_515' as it already exists.\n",
      "Skipping '0Xtp77A4zF4_8_84' as it already exists.\n",
      "Skipping '0Z2O6K1GiQk_117_133' as it already exists.\n",
      "Skipping '13VxOmABU_0_434_445' as it already exists.\n",
      "Skipping '13VxOmABU_0_70_82' as it already exists.\n",
      "Skipping '13VxOmABU_0_98_104' as it already exists.\n",
      "Skipping '18BUf9jXR34_51_58' as it already exists.\n",
      "Skipping '18BUf9jXR34_59_73' as it already exists.\n",
      "Skipping '18BUf9jXR34_74_87' as it already exists.\n",
      "Skipping '18BUf9jXR34_88_98' as it already exists.\n",
      "Skipping '18BUf9jXR34_99_154' as it already exists.\n",
      "Skipping '1alMJSJT_NQ_192_215' as it already exists.\n",
      "Skipping '1B7D6kASN5I_9_14' as it already exists.\n",
      "Skipping '1HPruyf3MAE_204_211' as it already exists.\n",
      "Skipping '1HPruyf3MAE_256_267' as it already exists.\n",
      "Skipping '1HPruyf3MAE_472_491' as it already exists.\n",
      "Skipping '1HwwIdnpTMY_453_460' as it already exists.\n",
      "Skipping '1ifHYTW_AU0_105_112' as it already exists.\n",
      "Skipping '1ifHYTW_AU0_113_126' as it already exists.\n",
      "Skipping '1ifHYTW_AU0_146_152' as it already exists.\n",
      "Skipping '1ifHYTW_AU0_269_275' as it already exists.\n",
      "Skipping '1ifHYTW_AU0_282_288' as it already exists.\n",
      "Skipping '1ifHYTW_AU0_334_344' as it already exists.\n",
      "Skipping '1ifHYTW_AU0_366_371' as it already exists.\n",
      "Skipping '1ifHYTW_AU0_444_455' as it already exists.\n",
      "Skipping '1ifHYTW_AU0_577_583' as it already exists.\n",
      "Skipping '1ifHYTW_AU0_674_680' as it already exists.\n",
      "Skipping '1ifHYTW_AU0_681_690' as it already exists.\n",
      "Skipping '1ifHYTW_AU0_727_732' as it already exists.\n",
      "Skipping '1ifHYTW_AU0_764_770' as it already exists.\n",
      "Skipping '1ifHYTW_AU0_88_95' as it already exists.\n",
      "Skipping '1iny6gC63-0_38_45' as it already exists.\n",
      "Skipping '1k9qcUaw_ZY_92_106' as it already exists.\n",
      "Skipping '1qXblBx-Ikc_117_176' as it already exists.\n",
      "Skipping '1qXblBx-Ikc_198_224' as it already exists.\n",
      "Skipping '1SoLeD-rU_k_332_340' as it already exists.\n",
      "Skipping '1SoLeD-rU_k_341_348' as it already exists.\n",
      "Skipping '1W6WCPBSR_s_38_44' as it already exists.\n",
      "Skipping '1W6WCPBSR_s_45_54' as it already exists.\n",
      "Skipping '1W6WCPBSR_s_55_64' as it already exists.\n",
      "Skipping '1W6WCPBSR_s_86_93' as it already exists.\n",
      "Skipping '1W6WCPBSR_s_94_105' as it already exists.\n",
      "Skipping '24k9Q4dPBg8_548_564' as it already exists.\n",
      "Skipping '28klGNDvFVA_12_44' as it already exists.\n",
      "Skipping '2DiQUX11YaY_12_20' as it already exists.\n",
      "Skipping '2DiQUX11YaY_188_202' as it already exists.\n",
      "Skipping '2DiQUX11YaY_218_226' as it already exists.\n",
      "Skipping '2DiQUX11YaY_26_39' as it already exists.\n",
      "Skipping '2DiQUX11YaY_272_279' as it already exists.\n",
      "Skipping '2DiQUX11YaY_40_47' as it already exists.\n",
      "Skipping '2DiQUX11YaY_4_11' as it already exists.\n",
      "Skipping '2DiQUX11YaY_92_100' as it already exists.\n",
      "Skipping '2iXfqNZ7hAQ_0_45' as it already exists.\n",
      "Skipping '2KQPgcYYDc4_107_118' as it already exists.\n",
      "Skipping '2l5-sry-rWg_312_318' as it already exists.\n",
      "Skipping '2l5-sry-rWg_322_329' as it already exists.\n",
      "Skipping '2l5-sry-rWg_338_344' as it already exists.\n",
      "Skipping '2Lze_h4_VXA_544_588' as it already exists.\n",
      "Skipping '2Lze_h4_VXA_589_600' as it already exists.\n",
      "Skipping '2Lze_h4_VXA_75_96' as it already exists.\n",
      "Skipping '2V_rJpY4BZc_192_201' as it already exists.\n",
      "Skipping '2ZcIrGekeNU_1231_1242' as it already exists.\n",
      "Skipping '2ZcIrGekeNU_350_363' as it already exists.\n",
      "Skipping '2ZcIrGekeNU_625_635' as it already exists.\n",
      "Skipping '2ZcIrGekeNU_662_669' as it already exists.\n",
      "Skipping '2_tnrvMIt2E_35_41' as it already exists.\n",
      "Skipping '2_tnrvMIt2E_42_55' as it already exists.\n",
      "Skipping '2_tnrvMIt2E_99_135' as it already exists.\n",
      "Skipping '3EUKTcGspIQ_282_305' as it already exists.\n",
      "Skipping '3EUKTcGspIQ_312_321' as it already exists.\n",
      "Skipping '3kgPCiPtpzg_119_131' as it already exists.\n",
      "Skipping '3kgPCiPtpzg_245_256' as it already exists.\n",
      "Skipping '3kgPCiPtpzg_311_321' as it already exists.\n",
      "Skipping '3kgPCiPtpzg_32_49' as it already exists.\n",
      "Skipping '3kgPCiPtpzg_335_349' as it already exists.\n",
      "Skipping '3kgPCiPtpzg_357_371' as it already exists.\n",
      "Skipping '3LQ8elG8Q0M_453_463' as it already exists.\n",
      "Skipping '3nk01iQPL1s_114_123' as it already exists.\n",
      "Skipping '3nk01iQPL1s_84_91' as it already exists.\n",
      "Skipping '3NNyX76PV1o_130_139' as it already exists.\n",
      "Skipping '3NNyX76PV1o_198_203' as it already exists.\n",
      "Skipping '3NNyX76PV1o_272_277' as it already exists.\n",
      "Skipping '3NNyX76PV1o_449_454' as it already exists.\n",
      "Skipping '3NNyX76PV1o_467_472' as it already exists.\n",
      "Skipping '3NNyX76PV1o_637_652' as it already exists.\n",
      "Skipping '3NNyX76PV1o_69_75' as it already exists.\n",
      "Skipping '3NNyX76PV1o_729_734' as it already exists.\n",
      "Skipping '3Tr4-Ggmric_149_163' as it already exists.\n",
      "Skipping '3Tr4-Ggmric_168_181' as it already exists.\n",
      "Skipping '3Tr4-Ggmric_193_208' as it already exists.\n",
      "Skipping '3Tr4-Ggmric_214_233' as it already exists.\n",
      "Skipping '3Tr4-Ggmric_64_74' as it already exists.\n",
      "Skipping '3tuMRFJ45Ok_8_25' as it already exists.\n",
      "Skipping '4271ylBgArU_38_45' as it already exists.\n",
      "Skipping '4271ylBgArU_62_71' as it already exists.\n",
      "Skipping '42Xl_83ouMk_10_26' as it already exists.\n",
      "Skipping '43EYzm0-H1M_82_132' as it already exists.\n",
      "Skipping '44Ej5SimL7w_163_208' as it already exists.\n",
      "Skipping '4AKKHZsrjgo_80_92' as it already exists.\n",
      "Skipping '4CI-3geDR58_142_161' as it already exists.\n",
      "Skipping '4cSMt4FB6wM_165_173' as it already exists.\n",
      "Skipping '4eWnWSX8dIk_70_81' as it already exists.\n",
      "Skipping '4fDe9f3cclA_167_173' as it already exists.\n",
      "Skipping '4fDe9f3cclA_263_271' as it already exists.\n",
      "Skipping '4fDe9f3cclA_362_370' as it already exists.\n",
      "Skipping '4fDe9f3cclA_456_461' as it already exists.\n",
      "Skipping '4iaWpLXPwWk_20_26' as it already exists.\n",
      "Skipping '4LFwzgwRyrY_12_18' as it already exists.\n",
      "Skipping '4LFwzgwRyrY_135_141' as it already exists.\n",
      "Skipping '4LFwzgwRyrY_265_311' as it already exists.\n",
      "Skipping '4LFwzgwRyrY_312_351' as it already exists.\n",
      "Skipping '4LFwzgwRyrY_352_378' as it already exists.\n",
      "Skipping '4LFwzgwRyrY_379_396' as it already exists.\n",
      "Skipping '4LFwzgwRyrY_397_404' as it already exists.\n",
      "Skipping '4LFwzgwRyrY_76_114' as it already exists.\n",
      "Skipping '4MeUoSBckKE_37_45' as it already exists.\n",
      "Skipping '4MHIpuvf4kM_42_50' as it already exists.\n",
      "Skipping '4mXdwU860pI_109_161' as it already exists.\n",
      "Skipping '4mXdwU860pI_162_189' as it already exists.\n",
      "Skipping '4mXdwU860pI_87_102' as it already exists.\n",
      "Skipping '4nK7qLS7Iq8_0_43' as it already exists.\n",
      "Skipping '4qJqyOWY8Q4_0_16' as it already exists.\n",
      "Skipping '4t2V806b_WE_333_426' as it already exists.\n",
      "Skipping '4vOMK0uGiq8_1405_1412' as it already exists.\n",
      "Skipping '54khTg3GHyc_29_37' as it already exists.\n",
      "Skipping '5Ada0XkOuNQ_0_88' as it already exists.\n",
      "Skipping '5C-9za0J0mE_190_211' as it already exists.\n",
      "Skipping '5C-9za0J0mE_254_264' as it already exists.\n",
      "Skipping '5Exh_P65m54_211_220' as it already exists.\n",
      "Skipping '5Exh_P65m54_231_243' as it already exists.\n",
      "Skipping '5Exh_P65m54_273_279' as it already exists.\n",
      "Skipping '5ff_uLoEBEo_125_133' as it already exists.\n",
      "Skipping '5ff_uLoEBEo_42_55' as it already exists.\n",
      "Skipping '5fhJSO5al8o_727_847' as it already exists.\n",
      "Skipping '5L4RqKd9MrU_6_12' as it already exists.\n",
      "Skipping '5MdcbbQEglI_363_381' as it already exists.\n",
      "Skipping '5RGiVwM2m18_109_115' as it already exists.\n",
      "Skipping '5RGiVwM2m18_149_155' as it already exists.\n",
      "Skipping '5RGiVwM2m18_18_24' as it already exists.\n",
      "Skipping '5RGiVwM2m18_70_76' as it already exists.\n",
      "Skipping '5wTgVHTMDNY_309_324' as it already exists.\n",
      "Skipping '5Yfx40Hz95I_39_67' as it already exists.\n",
      "Skipping '5_Zc9mFPTV8_38_74' as it already exists.\n",
      "Skipping '5_Zc9mFPTV8_75_124' as it already exists.\n",
      "Skipping '5_Zc9mFPTV8_7_37' as it already exists.\n",
      "Skipping '66iVMyHk9bw_12_21' as it already exists.\n",
      "Skipping '6BI1ltwsloE_0_30' as it already exists.\n",
      "Skipping '6BvXNmxC_F0_234_240' as it already exists.\n",
      "Skipping '6BvXNmxC_F0_275_283' as it already exists.\n",
      "Skipping '6BvXNmxC_F0_303_310' as it already exists.\n",
      "Skipping '6CZXldRSZD8_481_487' as it already exists.\n",
      "Skipping '6dHWDBvkR2g_129_135' as it already exists.\n",
      "Skipping '6dHWDBvkR2g_136_169' as it already exists.\n",
      "Skipping '6dHWDBvkR2g_54_80' as it already exists.\n",
      "Skipping '6dHWDBvkR2g_81_95' as it already exists.\n",
      "Skipping '6dHWDBvkR2g_96_128' as it already exists.\n",
      "Skipping '6EWOHAs2CeY_116_127' as it already exists.\n",
      "Skipping '6HQ08vnchIU_0_33' as it already exists.\n",
      "Skipping '6jTqT_Ucg6Q_76_92' as it already exists.\n",
      "Skipping '6TgrueI-L_E_256_262' as it already exists.\n",
      "Skipping '6tXN9qePKNA_682_688' as it already exists.\n",
      "Skipping '6XaKLILT7iE_132_141' as it already exists.\n",
      "Skipping '6zk5L6WxAXc_164_180' as it already exists.\n",
      "Skipping '6zk5L6WxAXc_181_220' as it already exists.\n",
      "Skipping '6zk5L6WxAXc_297_387' as it already exists.\n",
      "Skipping '720lf_07rgo_129_135' as it already exists.\n",
      "Skipping '720lf_07rgo_15_26' as it already exists.\n",
      "Skipping '720lf_07rgo_32_51' as it already exists.\n",
      "Skipping '720lf_07rgo_74_123' as it already exists.\n",
      "Skipping '74PQL3Qt6RI_0_35' as it already exists.\n",
      "Skipping '7F2TseXDyOg_0_20' as it already exists.\n",
      "Skipping '7GVetqf5198_147_157' as it already exists.\n",
      "Skipping '7GVetqf5198_440_449' as it already exists.\n",
      "Skipping '7GVetqf5198_466_476' as it already exists.\n",
      "Skipping '7hvxfSsodlM_6_13' as it already exists.\n",
      "Skipping '7KUPAZCXrvo_0_66' as it already exists.\n",
      "Skipping '7s-99QVpr0M_314_321' as it already exists.\n",
      "Skipping '7s-99QVpr0M_372_378' as it already exists.\n",
      "Skipping '7s-99QVpr0M_543_553' as it already exists.\n",
      "Skipping '7sBRE6MY1p8_0_79' as it already exists.\n",
      "Skipping '7tz19k-y-vQ_131_140' as it already exists.\n",
      "Skipping '7tz19k-y-vQ_184_191' as it already exists.\n",
      "Skipping '7xnB39oUqfI_300_420' as it already exists.\n",
      "Skipping '7xnB39oUqfI_438_446' as it already exists.\n",
      "Skipping '7yxJ1M4aK_w_39_53' as it already exists.\n",
      "Skipping '7zXOvVzflCA_205_214' as it already exists.\n",
      "Skipping '81ahuidFUWw_430_465' as it already exists.\n",
      "Skipping '81ahuidFUWw_799_818' as it already exists.\n",
      "Skipping '81ahuidFUWw_838_873' as it already exists.\n",
      "Skipping '81ahuidFUWw_909_919' as it already exists.\n",
      "Skipping '85oisikAKOI_494_537' as it already exists.\n",
      "Skipping '881uK5SDnFU_26_55' as it already exists.\n",
      "Skipping '881uK5SDnFU_56_83' as it already exists.\n",
      "Skipping '881uK5SDnFU_84_119' as it already exists.\n",
      "Skipping '8BQ-nVvJJMQ_125_143' as it already exists.\n",
      "Skipping '8BQ-nVvJJMQ_144_164' as it already exists.\n",
      "Skipping '8BQ-nVvJJMQ_165_187' as it already exists.\n",
      "Skipping '8BQ-nVvJJMQ_6_59' as it already exists.\n",
      "Skipping '8emfOel6ZZM_392_406' as it already exists.\n",
      "Skipping '8H_DSErYUZk_76_81' as it already exists.\n",
      "Skipping '8lsYuDsor08_104_111' as it already exists.\n",
      "Skipping '8M1_6RWFxtY_0_29' as it already exists.\n",
      "Skipping '8VCdF6fxOFk_145_218' as it already exists.\n",
      "Skipping '8xU5GZFVEd0_0_15' as it already exists.\n",
      "Skipping '934Befj4aD8_370_375' as it already exists.\n",
      "Skipping '9iBjqAmNiJA_379_420' as it already exists.\n",
      "Skipping '9iBjqAmNiJA_422_428' as it already exists.\n",
      "Skipping '9OIAgiB8rac_106_116' as it already exists.\n",
      "Skipping '9OIAgiB8rac_242_268' as it already exists.\n",
      "Skipping '9OIAgiB8rac_98_105' as it already exists.\n",
      "Skipping '9q7R9qFcrbI_102_112' as it already exists.\n",
      "Skipping '9q7R9qFcrbI_158_175' as it already exists.\n",
      "Skipping '9q7R9qFcrbI_30_36' as it already exists.\n",
      "Skipping '9q7R9qFcrbI_39_50' as it already exists.\n",
      "Skipping '9q7R9qFcrbI_56_77' as it already exists.\n",
      "Skipping '9q7R9qFcrbI_90_100' as it already exists.\n",
      "Skipping '9s2tAsyTFsw_79_91' as it already exists.\n",
      "Skipping '9xr9SBPnb58_32_61' as it already exists.\n",
      "Skipping '9YaFR5-MUPQ_151_180' as it already exists.\n",
      "Skipping '9YaFR5-MUPQ_54_69' as it already exists.\n",
      "Skipping '9Z-0GremE6g_0_68' as it already exists.\n",
      "Skipping '9Zs3YvVBPvI_11_19' as it already exists.\n",
      "Skipping 'A1Kc286gTGU_18_32' as it already exists.\n",
      "Skipping 'aEBejHvkYtg_189_200' as it already exists.\n",
      "Skipping 'aEBejHvkYtg_20_25' as it already exists.\n",
      "Skipping 'aEBejHvkYtg_72_77' as it already exists.\n",
      "Skipping 'AFigIK6zwvc_170_191' as it already exists.\n",
      "Skipping 'AFigIK6zwvc_24_31' as it already exists.\n",
      "Skipping 'AFigIK6zwvc_67_84' as it already exists.\n",
      "Skipping 'AFsdQDKd2ek_1033_1043' as it already exists.\n",
      "Skipping 'aHT6gKyNTp8_0_8' as it already exists.\n",
      "Skipping 'aHT6gKyNTp8_248_254' as it already exists.\n",
      "Skipping 'aHT6gKyNTp8_77_90' as it already exists.\n",
      "Skipping 'aiu5vERlUT4_215_229' as it already exists.\n",
      "Skipping 'Arh3ms6skIA_105_116' as it already exists.\n",
      "Skipping 'Arh3ms6skIA_121_138' as it already exists.\n",
      "Skipping 'Arh3ms6skIA_157_166' as it already exists.\n",
      "Skipping 'Arh3ms6skIA_296_302' as it already exists.\n",
      "Skipping 'Arh3ms6skIA_84_101' as it already exists.\n",
      "Skipping 'AStqdbLvQqs_0_20' as it already exists.\n",
      "Skipping 'ATj6Z89B680_61_70' as it already exists.\n",
      "Skipping 'ay7mKcpXQ6s_87_98' as it already exists.\n",
      "Skipping 'b6UyrHBJTKk_0_12' as it already exists.\n",
      "Skipping 'B7IZK2fO9m0_0_30' as it already exists.\n",
      "Skipping 'BaKPkrpKYI8_103_110' as it already exists.\n",
      "Skipping 'BaKPkrpKYI8_159_165' as it already exists.\n",
      "Skipping 'BjI79UzSsL4_0_32' as it already exists.\n",
      "Skipping 'BJLUd_rjMQg_374_380' as it already exists.\n",
      "Skipping 'BJLUd_rjMQg_388_394' as it already exists.\n",
      "Skipping 'BOi79Zuj8Jk_140_151' as it already exists.\n",
      "Skipping 'BOi79Zuj8Jk_287_295' as it already exists.\n",
      "Skipping 'Bqn_GzsrDqM_174_182' as it already exists.\n",
      "Skipping 'Bqn_GzsrDqM_67_74' as it already exists.\n",
      "Skipping 'BsqM8UWNiNo_107_120' as it already exists.\n",
      "Skipping 'BsqM8UWNiNo_138_148' as it already exists.\n",
      "Skipping 'BsqM8UWNiNo_151_166' as it already exists.\n",
      "Skipping 'BsqM8UWNiNo_18_40' as it already exists.\n",
      "Skipping 'BsqM8UWNiNo_53_59' as it already exists.\n",
      "Skipping 'BsqM8UWNiNo_73_82' as it already exists.\n",
      "Skipping 'bum0SKtk6Qw_82_88' as it already exists.\n",
      "Skipping 'Bw_pfRDJ_c4_529_551' as it already exists.\n",
      "Skipping 'BYWAsYayARk_0_19' as it already exists.\n",
      "Skipping 'bZp5U-gwQ5k_213_222' as it already exists.\n",
      "Skipping 'bZysB1KJKGA_176_182' as it already exists.\n",
      "Skipping 'bZysB1KJKGA_183_190' as it already exists.\n",
      "Skipping 'c2ecuoGWjJM_157_167' as it already exists.\n",
      "Skipping 'C85qIzJsFKA_35_45' as it already exists.\n",
      "Skipping 'CaLi7pN0Y2E_138_167' as it already exists.\n",
      "Skipping 'Cc110v8fRnI_106_120' as it already exists.\n",
      "Skipping 'Cc110v8fRnI_147_176' as it already exists.\n",
      "Skipping 'Cc110v8fRnI_180_189' as it already exists.\n",
      "Skipping 'Cc110v8fRnI_201_226' as it already exists.\n",
      "Skipping 'CcevP4Dgocw_55_66' as it already exists.\n",
      "Skipping 'cd9FI5DC0Bg_151_157' as it already exists.\n",
      "Skipping 'cd9FI5DC0Bg_453_468' as it already exists.\n",
      "Skipping 'cHADJkgoYwI_4_21' as it already exists.\n",
      "Skipping 'ci9uoC7fwJ0_13_29' as it already exists.\n",
      "Skipping 'CIejCqpSzIE_35_47' as it already exists.\n",
      "Skipping 'CIejCqpSzIE_57_69' as it already exists.\n",
      "Skipping 'cIiTdsvCjYo_126_132' as it already exists.\n",
      "Skipping 'cIiTdsvCjYo_64_71' as it already exists.\n",
      "Skipping 'Cioa-jes2Ls_885_909' as it already exists.\n",
      "Skipping 'Cn8PiqIXEjQ_107_117' as it already exists.\n",
      "Skipping 'Cn8PiqIXEjQ_139_157' as it already exists.\n",
      "Skipping 'Cn8PiqIXEjQ_158_169' as it already exists.\n",
      "Skipping 'Cn8PiqIXEjQ_34_44' as it already exists.\n",
      "Skipping 'Cp8UtHUvn8g_0_38' as it already exists.\n",
      "Skipping 'CqusBYOcaA4_437_448' as it already exists.\n",
      "Skipping 'CqusBYOcaA4_639_647' as it already exists.\n",
      "Skipping 'CtksAvk6myU_0_10' as it already exists.\n",
      "Skipping 'cuDL7PXKVMI_101_108' as it already exists.\n",
      "Skipping 'd2B2tV8gxtI_136_150' as it already exists.\n",
      "Skipping 'd2B2tV8gxtI_186_194' as it already exists.\n",
      "Skipping 'd2B2tV8gxtI_279_292' as it already exists.\n",
      "Skipping 'd2B2tV8gxtI_28_38' as it already exists.\n",
      "Skipping 'd7BW62RApU4_131_139' as it already exists.\n",
      "Skipping 'd7BW62RApU4_91_99' as it already exists.\n",
      "Skipping 'D8RppPVMWAM_0_18' as it already exists.\n",
      "Skipping 'D9W-KQmzi9Y_384_391' as it already exists.\n",
      "Skipping 'DFnWIxePOH8_527_537' as it already exists.\n",
      "Skipping 'dhBkWdeLHFQ_115_124' as it already exists.\n",
      "Skipping 'DNQFsRk5kW0_41_54' as it already exists.\n",
      "Skipping 'DOmSEGVuYAg_0_31' as it already exists.\n",
      "Skipping 'DOmSEGVuYAg_300_335' as it already exists.\n",
      "Skipping 'DOmSEGVuYAg_348_355' as it already exists.\n",
      "Skipping 'DOmSEGVuYAg_384_400' as it already exists.\n",
      "Skipping 'DOmSEGVuYAg_505_518' as it already exists.\n",
      "Skipping 'DpQSyrMgfpg_217_229' as it already exists.\n",
      "Skipping 'Dps2_fUosJo_0_40' as it already exists.\n",
      "Skipping 'Dps2_fUosJo_278_302' as it already exists.\n",
      "Skipping 'Dr9NRApKGJY_615_626' as it already exists.\n",
      "Skipping 'DV6xCdLpUmI_109_116' as it already exists.\n",
      "Skipping 'DV6xCdLpUmI_129_141' as it already exists.\n",
      "Skipping 'DV6xCdLpUmI_27_42' as it already exists.\n",
      "Skipping 'DV6xCdLpUmI_65_92' as it already exists.\n",
      "Skipping 'DWNuyUYB-jA_17_22' as it already exists.\n",
      "Skipping 'dxkYPpcsX9A_77_82' as it already exists.\n",
      "Skipping 'E-hyDICaWrQ_991_1009' as it already exists.\n",
      "Skipping 'e09Ig7lkxGs_258_270' as it already exists.\n",
      "Skipping 'E2BQNNwf6pA_2870_2880' as it already exists.\n",
      "Skipping 'earxxPKwFyg_31_42' as it already exists.\n",
      "Skipping 'earxxPKwFyg_54_65' as it already exists.\n",
      "Skipping 'earxxPKwFyg_96_107' as it already exists.\n",
      "Skipping 'EedFxiJJAMI_28_43' as it already exists.\n",
      "Skipping 'EedFxiJJAMI_62_76' as it already exists.\n",
      "Skipping 'EedFxiJJAMI_90_100' as it already exists.\n",
      "Skipping 'EGadMYDlCkI_10_23' as it already exists.\n",
      "Skipping 'eiGpNqHGw00_0_6' as it already exists.\n",
      "Skipping 'EjekbTQT2dw_129_155' as it already exists.\n",
      "Skipping 'Eq3QI54Mrno_28_36' as it already exists.\n",
      "Skipping 'eUcznRvP2Uw_0_16' as it already exists.\n",
      "Skipping 'Ext8wbSqJbs_132_161' as it already exists.\n",
      "Skipping 'Ez46D_sDg5w_121_132' as it already exists.\n",
      "Skipping 'F-51y-KFoiM_113_135' as it already exists.\n",
      "Skipping 'F-51y-KFoiM_299_320' as it already exists.\n",
      "Skipping 'F-51y-KFoiM_355_378' as it already exists.\n",
      "Skipping 'F-51y-KFoiM_36_55' as it already exists.\n",
      "Skipping 'f0lg_xnL4rg_126_134' as it already exists.\n",
      "Skipping 'F1drpxkXeNo_179_204' as it already exists.\n",
      "Skipping 'F4Jna44266A_46_52' as it already exists.\n",
      "Skipping 'fcyDTBjfL0o_112_122' as it already exists.\n",
      "Skipping 'fcyDTBjfL0o_191_201' as it already exists.\n",
      "Skipping 'fDjt6EVHq4E_0_8' as it already exists.\n",
      "Skipping 'fDjt6EVHq4E_44_58' as it already exists.\n",
      "Skipping 'fGJAm1iM1Vc_28_37' as it already exists.\n",
      "Skipping 'fGJAm1iM1Vc_87_96' as it already exists.\n",
      "Skipping 'FgWn75B0SPs_162_168' as it already exists.\n",
      "Skipping 'FHteFxMUToQ_273_291' as it already exists.\n",
      "Skipping 'FIMd5KFG1vQ_22_29' as it already exists.\n",
      "Skipping 'FIMd5KFG1vQ_268_292' as it already exists.\n",
      "Skipping 'FIMd5KFG1vQ_9_17' as it already exists.\n",
      "Skipping 'FL0qDVatFgk_246_259' as it already exists.\n",
      "Skipping 'FL0qDVatFgk_362_389' as it already exists.\n",
      "Skipping 'fl3k3Z3Tin4_12_17' as it already exists.\n",
      "Skipping 'fl3k3Z3Tin4_42_51' as it already exists.\n",
      "Skipping 'FQD5j4xeR8g_0_9' as it already exists.\n",
      "Skipping 'FQD5j4xeR8g_22_36' as it already exists.\n",
      "Skipping 'FQD5j4xeR8g_37_43' as it already exists.\n",
      "Skipping 'FuCNH7dqZxg_298_322' as it already exists.\n",
      "Skipping 'FuCNH7dqZxg_323_330' as it already exists.\n",
      "Skipping 'FW4vBcixJn4_0_15' as it already exists.\n",
      "Skipping 'G-_OBm_gw3c_634_641' as it already exists.\n",
      "Skipping 'G6zWzT_PLq4_51_65' as it already exists.\n",
      "Skipping 'GA6_pzGCioM_82_104' as it already exists.\n",
      "Skipping 'GD-0leFOllI_630_641' as it already exists.\n",
      "Skipping 'GD-0leFOllI_768_777' as it already exists.\n",
      "Skipping 'GgL_D4Xasaw_527_535' as it already exists.\n",
      "Skipping 'GHkt7tYwVwY_192_206' as it already exists.\n",
      "Skipping 'gis-qotycU8_227_235' as it already exists.\n",
      "Skipping 'glGvYiDWe-w_623_630' as it already exists.\n",
      "Skipping 'GLzsVzXtyH0_22_35' as it already exists.\n",
      "Skipping 'GLzsVzXtyH0_8_20' as it already exists.\n",
      "Skipping 'gnhfKhdTahI_0_7' as it already exists.\n",
      "Skipping 'gnhfKhdTahI_8_20' as it already exists.\n",
      "Skipping 'gol8Eek9VcE_142_151' as it already exists.\n",
      "Skipping 'gol8Eek9VcE_153_163' as it already exists.\n",
      "Skipping 'GSVtaMT5j2A_443_458' as it already exists.\n",
      "Skipping 'GsXOB9nJZI8_3_35' as it already exists.\n",
      "Skipping 'Gt1AWwtSqTU_155_162' as it already exists.\n",
      "Skipping 'GTk9evsaPW4_0_14' as it already exists.\n",
      "Skipping 'GV6F_cai_Vo_96_123' as it already exists.\n",
      "Skipping 'GXAOz9azkNg_143_151' as it already exists.\n",
      "Skipping 'gyE0Owe-WL4_109_122' as it already exists.\n",
      "Skipping 'gyE0Owe-WL4_127_133' as it already exists.\n",
      "Skipping 'GZQUV46bHVk_97_116' as it already exists.\n",
      "Skipping 'h2CFY6J8aiE_481_488' as it already exists.\n",
      "Skipping 'h2hwIDQkzBE_12_27' as it already exists.\n",
      "Skipping 'h2hwIDQkzBE_216_229' as it already exists.\n",
      "Skipping 'h2hwIDQkzBE_87_92' as it already exists.\n",
      "Skipping 'HbTzL6BPTqQ_73_87' as it already exists.\n",
      "Skipping 'HCucos4qGQw_193_203' as it already exists.\n",
      "Skipping 'HCucos4qGQw_36_52' as it already exists.\n",
      "Skipping 'HCucos4qGQw_60_68' as it already exists.\n",
      "Skipping 'HDNOB6TnHSI_4_12' as it already exists.\n",
      "Skipping 'hHKJruybYgQ_46_62' as it already exists.\n",
      "Skipping 'hNMvxvvC_z0_281_288' as it already exists.\n",
      "Skipping 'HoycHBRtUl8_0_19' as it already exists.\n",
      "Skipping 'HucUxlgXutk_0_34' as it already exists.\n",
      "Skipping 'HUWJl13C0dQ_104_118' as it already exists.\n",
      "Skipping 'HUWJl13C0dQ_164_191' as it already exists.\n",
      "Skipping 'HzOiJ87yNIg_206_233' as it already exists.\n",
      "Skipping 'HzOiJ87yNIg_20_44' as it already exists.\n",
      "Skipping 'HzOiJ87yNIg_237_262' as it already exists.\n",
      "Skipping 'I1hPndGcir4_73_106' as it already exists.\n",
      "Skipping 'i2c_oY7J4J4_0_10' as it already exists.\n",
      "Skipping 'i2c_oY7J4J4_23_29' as it already exists.\n",
      "Skipping 'i2c_oY7J4J4_78_85' as it already exists.\n",
      "Skipping 'I53PaTMsXbQ_244_250' as it already exists.\n",
      "Skipping 'i63DxymZp-0_1_7' as it already exists.\n",
      "Skipping 'i85kpkUSTfM_0_14' as it already exists.\n",
      "Skipping 'If7eg3vAKpE_24_64' as it already exists.\n",
      "Skipping 'If7eg3vAKpE_65_84' as it already exists.\n",
      "Skipping 'iSJqd8z1v20_0_13' as it already exists.\n",
      "Skipping 'issQGRCxt3A_281_290' as it already exists.\n",
      "Skipping 'ixZ6iG4Lieg_28_35' as it already exists.\n",
      "Skipping 'J4KLlvQIzfM_212_217' as it already exists.\n",
      "Skipping 'JAaB052VXIs_6_20' as it already exists.\n",
      "Skipping 'JNCYkZxsWUc_659_670' as it already exists.\n",
      "Skipping 'JuuF1Qq7mmY_134_150' as it already exists.\n",
      "Skipping 'jwEJ1ST3vxA_103_110' as it already exists.\n",
      "Skipping 'jwEJ1ST3vxA_209_224' as it already exists.\n",
      "Skipping 'JYq5t0b6F1Y_0_17' as it already exists.\n",
      "Skipping 'K18G2iS4MNU_37_51' as it already exists.\n",
      "Skipping 'k52kVVkQp5A_228_236' as it already exists.\n",
      "Skipping 'K6H9sY6hIeA_146_173' as it already exists.\n",
      "Skipping 'K6H9sY6hIeA_37_54' as it already exists.\n",
      "Skipping 'K6H9sY6hIeA_56_74' as it already exists.\n",
      "Skipping 'K6H9sY6hIeA_79_99' as it already exists.\n",
      "Skipping 'Ka2Heek0PBc_479_490' as it already exists.\n",
      "Skipping 'KauRc4MN-iQ_9_15' as it already exists.\n",
      "Skipping 'KJ5B9LYSm5M_115_126' as it already exists.\n",
      "Skipping 'KJ5B9LYSm5M_39_45' as it already exists.\n",
      "Skipping 'KlB1iSASNqo_143_160' as it already exists.\n",
      "Skipping 'KlB1iSASNqo_76_82' as it already exists.\n",
      "Skipping 'KQqFixbb-o8_120_143' as it already exists.\n",
      "Skipping 'KQqFixbb-o8_144_172' as it already exists.\n",
      "Skipping 'KQqFixbb-o8_173_189' as it already exists.\n",
      "Skipping 'KQqFixbb-o8_17_25' as it already exists.\n",
      "Skipping 'KQqFixbb-o8_242_254' as it already exists.\n",
      "Skipping 'KQqFixbb-o8_26_58' as it already exists.\n",
      "Skipping 'KQqFixbb-o8_276_303' as it already exists.\n",
      "Skipping 'KQqFixbb-o8_90_101' as it already exists.\n",
      "Skipping 'ktm4jIVuXKM_83_95' as it already exists.\n",
      "Skipping 'KxCudfxrdcI_0_13' as it already exists.\n",
      "Skipping 'KxCudfxrdcI_136_148' as it already exists.\n",
      "Skipping 'K_IpzROt3-Y_182_191' as it already exists.\n",
      "Skipping 'L4H-nBgiFmg_113_134' as it already exists.\n",
      "Skipping 'L4H-nBgiFmg_212_226' as it already exists.\n",
      "Skipping 'LC6uhWGDf8E_210_227' as it already exists.\n",
      "Skipping 'LRrkx8cDqWo_135_142' as it already exists.\n",
      "Skipping 'LYuWjliaHqY_824_838' as it already exists.\n",
      "Skipping 'm0N9C4BOf5c_251_263' as it already exists.\n",
      "Skipping 'mDNtTDqfTlY_246_255' as it already exists.\n",
      "Skipping 'MnOzFlfcK3g_26_37' as it already exists.\n",
      "Skipping 'mO9-kPzdECU_524_531' as it already exists.\n",
      "Skipping 'MQg4p2xv1XQ_39_54' as it already exists.\n",
      "Skipping 'Mt89AymlstA_30_48' as it already exists.\n",
      "Skipping 'MuwOOx1Wzfk_16_33' as it already exists.\n",
      "Skipping 'MuwOOx1Wzfk_88_104' as it already exists.\n",
      "Skipping 'MVNPx6_PzuI_0_24' as it already exists.\n",
      "Skipping 'MWplCf4fuKM_180_188' as it already exists.\n",
      "Skipping 'N8GQVqtk028_6_12' as it already exists.\n",
      "Skipping 'N8GQVqtk028_80_86' as it already exists.\n",
      "Skipping 'nnWh8tKfMbk_154_168' as it already exists.\n",
      "Skipping 'Nv1ItNQ8y_g_231_241' as it already exists.\n",
      "Skipping 'NX3QGnK8dGE_104_119' as it already exists.\n",
      "Skipping 'NX3QGnK8dGE_120_135' as it already exists.\n",
      "Skipping 'o1W3jADOA08_179_189' as it already exists.\n",
      "Skipping 'o4xuiPTj3a4_17_31' as it already exists.\n",
      "Skipping 'o61fbnPCYqI_127_134' as it already exists.\n",
      "Skipping 'OabhIVN8Pps_1_22' as it already exists.\n",
      "Skipping 'OjXAmWvL3HY_197_214' as it already exists.\n",
      "Skipping 'OPj9dJRCcug_0_33' as it already exists.\n",
      "Skipping 'OwchMqCYaF4_0_14' as it already exists.\n",
      "Skipping 'OwchMqCYaF4_70_77' as it already exists.\n",
      "Skipping 'P2Kzw86IfQw_0_59' as it already exists.\n",
      "Skipping 'p3sDuX8b8qU_154_160' as it already exists.\n",
      "Skipping 'p3sDuX8b8qU_213_219' as it already exists.\n",
      "Skipping 'p3sDuX8b8qU_85_101' as it already exists.\n",
      "Skipping 'p4MdrvBrXSg_75_81' as it already exists.\n",
      "Skipping 'p4MdrvBrXSg_85_91' as it already exists.\n",
      "Skipping 'p4MdrvBrXSg_94_109' as it already exists.\n",
      "Skipping 'P9DuXLZ6hzY_231_244' as it already exists.\n",
      "Skipping 'pEy6a_PDz1c_30_39' as it already exists.\n",
      "Skipping 'PlPZ-npnGEk_177_196' as it already exists.\n",
      "Skipping 'PLuIRSMK5eo_3_9' as it already exists.\n",
      "Skipping 'pSEdQGGjB8Y_70_78' as it already exists.\n",
      "Skipping 'Q1h0PaJFiXI_21_45' as it already exists.\n",
      "Skipping 'Q2rG9joNzmE_149_156' as it already exists.\n",
      "Skipping 'Q2rG9joNzmE_175_187' as it already exists.\n",
      "Skipping 'Q2rG9joNzmE_367_375' as it already exists.\n",
      "Skipping 'Q2rG9joNzmE_44_58' as it already exists.\n",
      "Skipping 'Q2rG9joNzmE_77_92' as it already exists.\n",
      "Skipping 'Q2rG9joNzmE_93_109' as it already exists.\n",
      "Skipping 'QD25zgSsUiM_400_413' as it already exists.\n",
      "Skipping 'QR6fWfC1Lh0_153_164' as it already exists.\n",
      "Skipping 'qsIaf3jVTxI_0_15' as it already exists.\n",
      "Skipping 'qX6OAWmG6o0_27_41' as it already exists.\n",
      "Skipping 'QzgiCkZLbXw_70_98' as it already exists.\n",
      "Skipping 'R6ggjJ69nOU_21_32' as it already exists.\n",
      "Skipping 'r9yVHYeg9xk_813_819' as it already exists.\n",
      "Skipping 'R9zpXFvEWG4_0_18' as it already exists.\n",
      "Skipping 'rCAUE5iqMeg_173_180' as it already exists.\n",
      "Skipping 'rjIgwHu1HOc_75_85' as it already exists.\n",
      "Skipping 'RmYDQu8RtnM_42_49' as it already exists.\n",
      "Skipping 'Rx-JSwMsfvs_103_111' as it already exists.\n",
      "Skipping 'Ry0Dm6yz8cA_100_110' as it already exists.\n",
      "Skipping 'Ry0Dm6yz8cA_37_49' as it already exists.\n",
      "Skipping 'Ry0Dm6yz8cA_60_73' as it already exists.\n",
      "Skipping 'Ry0Dm6yz8cA_93_99' as it already exists.\n",
      "Skipping 'S8yM3npjwn8_28_39' as it already exists.\n",
      "Skipping 'S8yM3npjwn8_52_62' as it already exists.\n",
      "Skipping 'S8yM3npjwn8_63_79' as it already exists.\n",
      "Skipping 'S9vBXV-tHEM_20_27' as it already exists.\n",
      "Skipping 'S9vBXV-tHEM_223_239' as it already exists.\n",
      "Skipping 'S9vBXV-tHEM_242_261' as it already exists.\n",
      "Skipping 'S9vBXV-tHEM_290_297' as it already exists.\n",
      "Skipping 'SEYuVQ2-ov4_198_204' as it already exists.\n",
      "Skipping 'SEYuVQ2-ov4_388_394' as it already exists.\n",
      "Skipping 'SEYuVQ2-ov4_462_469' as it already exists.\n",
      "Skipping 'SM4dmuL8KKw_13_28' as it already exists.\n",
      "Skipping 'SnrlHsMsG9o_322_329' as it already exists.\n",
      "Skipping 'sPegLaBqB-k_0_6' as it already exists.\n",
      "Skipping 'sPegLaBqB-k_35_42' as it already exists.\n",
      "Skipping 'sPegLaBqB-k_47_53' as it already exists.\n",
      "Skipping 'sPegLaBqB-k_64_77' as it already exists.\n",
      "Skipping 'sTHXIzHPyqE_16_23' as it already exists.\n",
      "Skipping 'sTHXIzHPyqE_24_29' as it already exists.\n",
      "Skipping 'Su1YLAjty-U_274_281' as it already exists.\n",
      "Skipping 'sZdRTEjdbmw_209_224' as it already exists.\n",
      "Skipping 'T2h6Yvxf8CA_126_133' as it already exists.\n",
      "Skipping 'T2h6Yvxf8CA_597_605' as it already exists.\n",
      "Skipping 'T6dCYE56etM_0_19' as it already exists.\n",
      "Skipping 'T6dCYE56etM_20_32' as it already exists.\n",
      "Skipping 'T6dCYE56etM_35_47' as it already exists.\n",
      "Skipping 'TJXzIX8tl2M_36_41' as it already exists.\n",
      "Skipping 'tnthhVYcH3I_220_229' as it already exists.\n",
      "Skipping 'Twfy_jWEDt4_108_117' as it already exists.\n",
      "Skipping 'Twfy_jWEDt4_135_142' as it already exists.\n",
      "Skipping 'Twfy_jWEDt4_188_194' as it already exists.\n",
      "Skipping 'Twfy_jWEDt4_213_219' as it already exists.\n",
      "Skipping 'Twfy_jWEDt4_40_46' as it already exists.\n",
      "Skipping 'Twfy_jWEDt4_88_94' as it already exists.\n",
      "Skipping 'uA8BBbJPJO0_19_25' as it already exists.\n",
      "Skipping 'uGm4ZFFaLK8_233_241' as it already exists.\n",
      "Skipping 'uGm4ZFFaLK8_96_107' as it already exists.\n",
      "Skipping 'UhDgpXWkFHE_279_286' as it already exists.\n",
      "Skipping 'Upu96iQH_d0_196_213' as it already exists.\n",
      "Skipping 'UQZxgJBLVGg_62_68' as it already exists.\n",
      "Skipping 'uT8kWHek_ZE_186_199' as it already exists.\n",
      "Skipping 'uT8kWHek_ZE_473_479' as it already exists.\n",
      "Skipping 'Vsgw5kzcKT0_209_220' as it already exists.\n",
      "Skipping 'Vsgw5kzcKT0_373_380' as it already exists.\n",
      "Skipping 'VsO9J5KtrR4_109_122' as it already exists.\n",
      "Skipping 'vuPLV3EXpjs_5_17' as it already exists.\n",
      "Skipping 'Vxzjzq5I-A4_71_80' as it already exists.\n",
      "Skipping 'Vxzjzq5I-A4_81_90' as it already exists.\n",
      "Skipping 'Vxzjzq5I-A4_91_97' as it already exists.\n",
      "Skipping 'WaU-9lwKdJs_164_169' as it already exists.\n",
      "Skipping 'WaU-9lwKdJs_262_272' as it already exists.\n",
      "Skipping 'WAUYbr5YE2U_0_13' as it already exists.\n",
      "Skipping 'WIgXBvSuqjI_206_212' as it already exists.\n",
      "Skipping 'WIgXBvSuqjI_27_32' as it already exists.\n",
      "Skipping 'WIgXBvSuqjI_91_96' as it already exists.\n",
      "Skipping 'wJChGIeWsEM_220_229' as it already exists.\n",
      "Skipping 'WKbN-iY7DSU_27_34' as it already exists.\n",
      "Skipping 'WKbN-iY7DSU_42_53' as it already exists.\n",
      "Skipping 'WKyaBl0EJec_505_514' as it already exists.\n",
      "Skipping 'wt9UHXJ1kRU_0_15' as it already exists.\n",
      "Skipping 'wYtP1cqH7yE_72_77' as it already exists.\n",
      "Skipping 'xDimkgrk6Yc_16_24' as it already exists.\n",
      "Skipping 'XKWYzv19pFY_85_93' as it already exists.\n",
      "Skipping 'xnHDu-oW7_Y_871_879' as it already exists.\n",
      "Skipping 'xsGabFKUhoY_122_132' as it already exists.\n",
      "Skipping 'XU9ii-Wygnk_0_11' as it already exists.\n",
      "Skipping 'xUkZPp9wqss_16_22' as it already exists.\n",
      "Skipping 'y13F8SXvLP0_215_222' as it already exists.\n",
      "Skipping 'y3TEkacYXUk_44_56' as it already exists.\n",
      "Skipping 'y4o7kpqrPHA_137_143' as it already exists.\n",
      "Skipping 'Y5mFh6F3a5I_100_114' as it already exists.\n",
      "Skipping 'Y5mFh6F3a5I_246_259' as it already exists.\n",
      "Skipping 'yATq9ymZSHM_59_73' as it already exists.\n",
      "Skipping 'yBJ2C6Vxxvs_158_166' as it already exists.\n",
      "Skipping 'yFHjS6vuFI0_26_40' as it already exists.\n",
      "Skipping 'yIG-xMnQUWg_69_81' as it already exists.\n",
      "Skipping 'yIG-xMnQUWg_85_92' as it already exists.\n",
      "Skipping 'Yms0Ui-dfx4_26_42' as it already exists.\n",
      "Skipping 'Yqv00bt7BNU_180_192' as it already exists.\n",
      "Skipping 'Yqv00bt7BNU_75_82' as it already exists.\n",
      "Skipping 'YXnHCoKw_sg_44_51' as it already exists.\n",
      "Skipping 'z7IlQuOqjp4_0_14' as it already exists.\n",
      "Skipping 'z7IlQuOqjp4_111_124' as it already exists.\n",
      "Skipping 'z7IlQuOqjp4_135_147' as it already exists.\n",
      "Skipping 'z7IlQuOqjp4_62_79' as it already exists.\n",
      "Skipping 'z9W_KanUqjs_114_127' as it already exists.\n",
      "Skipping 'z9W_KanUqjs_16_28' as it already exists.\n",
      "Skipping 'z9W_KanUqjs_222_231' as it already exists.\n",
      "Skipping 'zc4j796JGWU_112_123' as it already exists.\n",
      "Skipping 'ZfAykylM3Bo_281_290' as it already exists.\n",
      "Skipping 'ZKpVxaBOBm0_0_15' as it already exists.\n",
      "Skipping 'ZVdkjBoZiEA_105_114' as it already exists.\n",
      "Skipping 'ZVdkjBoZiEA_133_140' as it already exists.\n",
      "Skipping 'ZVdkjBoZiEA_76_89' as it already exists.\n",
      "Skipping 'ZZMOjSFMwls_71_77' as it already exists.\n",
      "Skipping '_9_e81xxHlA_94_102' as it already exists.\n",
      "Skipping '_F5SH2qQsv8_312_322' as it already exists.\n",
      "Skipping '_jKihXROX0E_81_92' as it already exists.\n",
      "Skipping '_ROpbCd4SRY_79_86' as it already exists.\n",
      "Skipping '_SKiA0TM-Xw_202_211' as it already exists.\n",
      "Skipping '_Z6E2BumgQc_223_240' as it already exists.\n",
      "All sequences have been processed.\n",
      "Skipping '0azuS0l_DII_146_164' as it already exists.\n",
      "Skipping '0azuS0l_DII_310_318' as it already exists.\n",
      "Skipping '0azuS0l_DII_573_580' as it already exists.\n",
      "Skipping '0azuS0l_DII_681_688' as it already exists.\n",
      "Skipping '0azuS0l_DII_68_75' as it already exists.\n",
      "Skipping '0azuS0l_DII_751_763' as it already exists.\n",
      "Skipping '0MvF6VAmFtY_634_643' as it already exists.\n",
      "Skipping 'aj3F-Rgx3aU_336_344' as it already exists.\n",
      "Skipping 'azqnzhlinTY_0_10' as it already exists.\n",
      "Skipping 'bfo8luLDDRk_178_183' as it already exists.\n",
      "Skipping 'cDHxT669GU0_62_68' as it already exists.\n",
      "Skipping 'cGMlPDlY094_146_159' as it already exists.\n",
      "Skipping 'cymW13H04Zw_116_128' as it already exists.\n",
      "Skipping 'cymW13H04Zw_67_72' as it already exists.\n",
      "Skipping 'dDam40Ot5l4_605_611' as it already exists.\n",
      "Skipping 'DgOFYVXzEVE_169_174' as it already exists.\n",
      "Skipping 'DgOFYVXzEVE_200_207' as it already exists.\n",
      "Skipping 'DgOFYVXzEVE_248_259' as it already exists.\n",
      "Skipping 'dSnj-D4Zi_k_312_320' as it already exists.\n",
      "Skipping 'dSnj-D4Zi_k_57_67' as it already exists.\n",
      "Skipping 'e5QeBtwrqNc_91_97' as it already exists.\n",
      "Skipping 'Ebdw7-0BTig_0_12' as it already exists.\n",
      "Skipping 'EcimSr4NrF4_38_45' as it already exists.\n",
      "Skipping 'Edc6EyWicNE_44_49' as it already exists.\n",
      "Skipping 'EfEfmdx5TQo_77_88' as it already exists.\n",
      "Skipping 'EXuwpanP2Y0_14_23' as it already exists.\n",
      "Skipping 'fWd8iH0uBSg_609_617' as it already exists.\n",
      "Skipping 'fX3Jup9TGb8_34_47' as it already exists.\n",
      "Skipping 'f_-7co3341w_95_106' as it already exists.\n",
      "Skipping 'g5ONCWDhie0_49_63' as it already exists.\n",
      "Skipping 'gbskCIkYjRU_301_306' as it already exists.\n",
      "Skipping 'gx3UgBO6AA0_294_300' as it already exists.\n",
      "Skipping 'gx3UgBO6AA0_301_306' as it already exists.\n",
      "Skipping 'h02mh5aQNIU_0_8' as it already exists.\n",
      "Skipping 'H2p7FYBPdiY_148_154' as it already exists.\n",
      "Skipping 'HJ5MpzrFEdA_76_83' as it already exists.\n",
      "Skipping 'HlvCV1YtJFI_127_132' as it already exists.\n",
      "Skipping 'HwuRL6tYFcI_201_321' as it already exists.\n",
      "Skipping 'IL4Li4IRddI_8_14' as it already exists.\n",
      "Skipping 'IsF53JpBMlk_177_183' as it already exists.\n",
      "Skipping 'iyzA44SPe2M_281_287' as it already exists.\n",
      "Skipping 'i_S5CPEo5oQ_173_180' as it already exists.\n",
      "Skipping 'i_S5CPEo5oQ_52_58' as it already exists.\n",
      "Skipping 'JwdNbTFCH6c_80_92' as it already exists.\n",
      "Skipping 'jwuDWXOqP8g_461_469' as it already exists.\n",
      "Skipping 'koIhXO0AotA_148_158' as it already exists.\n",
      "Skipping 'kReb8IIt9X8_78_85' as it already exists.\n",
      "Skipping 'kyJHOunump0_71_76' as it already exists.\n",
      "Skipping 'l2ibXy7BdK8_259_264' as it already exists.\n",
      "Skipping 'lChkIucgK20_15_21' as it already exists.\n",
      "Skipping 'leU8eHtIbww_92_103' as it already exists.\n",
      "Skipping 'niD-SRvDt3A_102_108' as it already exists.\n",
      "Skipping 'o0yglSMf7sA_101_107' as it already exists.\n",
      "Skipping 'o0yglSMf7sA_441_448' as it already exists.\n",
      "Skipping 'oacelnX3VSQ_55_61' as it already exists.\n",
      "Skipping 'OkesuKWybHY_331_338' as it already exists.\n",
      "Skipping 'oPe1EBPOVvw_284_294' as it already exists.\n",
      "Skipping 'PUK7cQyfGW4_32_41' as it already exists.\n",
      "Skipping 'QuncAUHpl-8_448_458' as it already exists.\n",
      "Skipping 'q_zjKkwv9vY_71_82' as it already exists.\n",
      "Skipping 'r8oHUdmBRUA_58_73' as it already exists.\n",
      "Skipping 'RAnP0wtahvk_117_122' as it already exists.\n",
      "Skipping 'RAnP0wtahvk_235_243' as it already exists.\n",
      "Skipping 'RtWKTpsUZAY_100_106' as it already exists.\n",
      "Skipping 'ruRcqnaiK6s_359_368' as it already exists.\n",
      "Skipping 'RWX4BoXDqPk_62_74' as it already exists.\n",
      "Skipping 'RyiLIIx2sEI_182_190' as it already exists.\n",
      "Skipping 'SdO54K9Cvgk_53_61' as it already exists.\n",
      "Skipping 'sJuREx-_3Ys_22_30' as it already exists.\n",
      "Skipping 'T89pLEoTIhs_0_5' as it already exists.\n",
      "Skipping 'tzSwICEJpc4_98_103' as it already exists.\n",
      "Skipping 't_4K0fNaed0_96_106' as it already exists.\n",
      "Skipping 'wv4eU_o0wZA_76_86' as it already exists.\n",
      "Skipping 'x-ab7Unn0o8_1303_1312' as it already exists.\n",
      "Skipping 'XU0Qn3hPpFE_62_71' as it already exists.\n",
      "Skipping 'Y2q8sbJDLEw_38_45' as it already exists.\n",
      "Skipping 'YwhMh28Ois8_387_393' as it already exists.\n",
      "Skipping 'yZde6KWbWuM_0_7' as it already exists.\n",
      "Skipping 'z1UiJsYPGzA_262_268' as it already exists.\n",
      "Skipping '_Ogj-Oy-l5M_3_9' as it already exists.\n",
      "All sequences have been processed.\n"
     ]
    }
   ],
   "source": [
    "# Function to check if a sequence exists in an HDF5 file\n",
    "def sequence_exists(h5_file_path, sequence_name):\n",
    "    if os.path.exists(h5_file_path):\n",
    "        with h5py.File(h5_file_path, 'r') as h5f:\n",
    "            return sequence_name in h5f\n",
    "    return False\n",
    "\n",
    "# Function to parse info.xml and extract relevant data\n",
    "def parse_info_xml(info_xml_path):\n",
    "    tree = ET.parse(info_xml_path)\n",
    "    root = tree.getroot()\n",
    "    info_data = {elem.tag: elem.text for elem in root.find('doc')}\n",
    "    return info_data\n",
    "\n",
    "# Function to save frames, annotations, and info.xml data to HDF5 files\n",
    "def save_frames_and_annotations_to_hdf5(data_path, h5_file_path, individual_h5_dir, batch_size=10):\n",
    "    sequence_count = 0\n",
    "\n",
    "    with h5py.File(h5_file_path, 'a') as h5f:\n",
    "        for dir_name in os.listdir(data_path):\n",
    "            dir_path = os.path.join(data_path, dir_name)\n",
    "\n",
    "            if os.path.isdir(dir_path):\n",
    "                sequence_name = os.path.basename(dir_path)\n",
    "                individual_h5_file = os.path.join(individual_h5_dir, f\"{dir_name}.h5\")\n",
    "\n",
    "                if sequence_exists(h5_file_path, sequence_name) and sequence_exists(individual_h5_file, sequence_name):\n",
    "                    print(f\"Skipping '{sequence_name}' as it already exists.\")\n",
    "                    continue\n",
    "\n",
    "                with h5py.File(individual_h5_file, 'a') as h5_individual:\n",
    "                    for subdir_name in os.listdir(dir_path):\n",
    "                        subdir_path = os.path.join(dir_path, subdir_name)\n",
    "\n",
    "                        if subdir_name == \"img1\":\n",
    "                            frame_dataset = h5f.create_dataset(\n",
    "                                f\"{sequence_name}/frames\", shape=(0, 224, 224, 3),\n",
    "                                maxshape=(None, 224, 224, 3), chunks=True, dtype='uint8'\n",
    "                            )\n",
    "                            ind_frame_dataset = h5_individual.create_dataset(\n",
    "                                f\"{sequence_name}/frames\", shape=(0, 224, 224, 3),\n",
    "                                maxshape=(None, 224, 224, 3), chunks=True, dtype='uint8'\n",
    "                            )\n",
    "\n",
    "                            for img_name in sorted(os.listdir(subdir_path)):\n",
    "                                img_path = os.path.join(subdir_path, img_name)\n",
    "                                img = cv2.imread(img_path)\n",
    "                                if img is not None:\n",
    "                                    resized_img = cv2.resize(img, (224, 224))\n",
    "                                    frame_dataset.resize(frame_dataset.shape[0] + 1, axis=0)\n",
    "                                    frame_dataset[-1] = resized_img\n",
    "                                    ind_frame_dataset.resize(ind_frame_dataset.shape[0] + 1, axis=0)\n",
    "                                    ind_frame_dataset[-1] = resized_img\n",
    "\n",
    "                            annotations_path = os.path.join(dir_path, \"gt\", \"path_annots.json\")\n",
    "                            if os.path.exists(annotations_path):\n",
    "                                with open(annotations_path, 'r') as f:\n",
    "                                    annotations = json.load(f)\n",
    "                                h5f[f\"{sequence_name}/annotations\"] = json.dumps(annotations).encode('utf-8')\n",
    "                                h5_individual[f\"{sequence_name}/annotations\"] = json.dumps(annotations).encode('utf-8')\n",
    "\n",
    "                            info_xml_path = os.path.join(dir_path, \"info.xml\")\n",
    "                            if os.path.exists(info_xml_path):\n",
    "                                info_data = parse_info_xml(info_xml_path)\n",
    "                                for key, value in info_data.items():\n",
    "                                    h5f[f\"{sequence_name}\"].attrs[key] = value\n",
    "                                    h5_individual[f\"{sequence_name}\"].attrs[key] = value\n",
    "\n",
    "                            print(f\"Saved sequence '{sequence_name}'.\")\n",
    "\n",
    "                    sequence_count += 1\n",
    "                    if sequence_count % batch_size == 0:\n",
    "                        print(f\"Clearing RAM after processing {sequence_count} sequences...\")\n",
    "                        gc.collect()\n",
    "\n",
    "    print(\"All sequences have been processed.\")\n",
    "\n",
    "# Save training and test data\n",
    "save_frames_and_annotations_to_hdf5(TRAIN_PATH, TRAIN_HDF5_FILE, TRAIN_INDIVIDUAL_H5_DIR)\n",
    "save_frames_and_annotations_to_hdf5(TEST_PATH, TEST_HDF5_FILE, TEST_INDIVIDUAL_H5_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b20bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to process a sequence\n",
    "# def process_sequence(sequence_name):\n",
    "#     individual_h5_file = os.path.join(TRAIN_INDIVIDUAL_H5_DIR, f\"{sequence_name}.h5\")\n",
    "    \n",
    "#     if not os.path.exists(individual_h5_file):\n",
    "#         print(f\"Error: Individual HDF5 file for '{sequence_name}' does not exist.\")\n",
    "#         return\n",
    "\n",
    "#     with h5py.File(individual_h5_file, 'r') as h5_individual:\n",
    "#         frames = h5_individual[sequence_name]['frames'][:]\n",
    "        \n",
    "#         # Load detections from det_rcnn.txt\n",
    "#         det_rcnn_path = os.path.join(TRAIN_PATH, sequence_name, \"det\", \"det_rcnn.txt\")\n",
    "#         detections = []\n",
    "\n",
    "#         if os.path.exists(det_rcnn_path):\n",
    "#             with open(det_rcnn_path, 'r') as f:\n",
    "#                 det_data = f.readlines()\n",
    "#                 for line in det_data:\n",
    "#                     parts = line.strip().split(',')\n",
    "#                     if len(parts) >= 7:\n",
    "#                         detections.append({\n",
    "#                             \"frame_number\": int(float(parts[0])),  # Convert to float first then to int\n",
    "#                             \"class_id\": int(float(parts[1])),      # Convert to float first then to int\n",
    "#                             \"score\": float(parts[2]),\n",
    "#                             \"bbox\": [float(part) for part in parts[3:7]]\n",
    "#                         })\n",
    "\n",
    "#         # Extract features from frames using the CNN model\n",
    "#         train_features = extract_features_from_frames(frames, cnn_model)\n",
    "        \n",
    "#         # Save features in the specified directory\n",
    "#         np.save(os.path.join(FEATURES_DIR, f\"{sequence_name}_features.npy\"), train_features)\n",
    "#         print(f\"Extracted features for sequence '{sequence_name}': {train_features.shape}\")\n",
    "\n",
    "#         # Clear memory after processing each sequence\n",
    "#         del frames\n",
    "#         del detections\n",
    "#         gc.collect()  # Force garbage collection\n",
    "\n",
    "# # Process each sequence in the training set\n",
    "# for dir_name in os.listdir(TRAIN_PATH):\n",
    "#     sequence_name = os.path.basename(dir_name)\n",
    "#     process_sequence(sequence_name)\n",
    "\n",
    "# print(\"All sequences have been processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d41a36",
   "metadata": {},
   "source": [
    "# 3. CNN Model Definition and Feature Extraction\n",
    "This section defines the ResNet-50 model for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8b5787c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features for sequence '-bnYpCiwV2Q_301_308': (174, 2048)\n",
      "Extracted features for sequence '-cKE8pyfcZc_38_46': (239, 2048)\n",
      "Extracted features for sequence '-DGzHCfmv5k_23_30': (174, 2048)\n",
      "Extracted features for sequence '-DGzHCfmv5k_92_97': (125, 2048)\n",
      "Extracted features for sequence '-fe32cvcpDI_378_388': (239, 2048)\n",
      "Extracted features for sequence '-kX6T3DkExg_85_94': (269, 2048)\n",
      "Extracted features for sequence '-LRxcWBl7P8_112_124': (299, 2048)\n",
      "Extracted features for sequence '0-ENiq-1R5M_226_240': (335, 2048)\n",
      "Extracted features for sequence '00np___nE5s_314_322': (238, 2048)\n",
      "Extracted features for sequence '00np___nE5s_394_404': (298, 2048)\n",
      "Extracted features for sequence '00np___nE5s_465_471': (179, 2048)\n",
      "Extracted features for sequence '00np___nE5s_481_506': (750, 2048)\n",
      "Extracted features for sequence '03tAll3Rnb8_145_160': (449, 2048)\n",
      "Extracted features for sequence '08u_l3VMtFM_204_243': (934, 2048)\n",
      "Extracted features for sequence '08u_l3VMtFM_848_861': (312, 2048)\n",
      "Extracted features for sequence '08u_l3VMtFM_93_116': (551, 2048)\n",
      "Extracted features for sequence '08xgGFk5fds_739_749': (249, 2048)\n",
      "Extracted features for sequence '08xgGFk5fds_762_768': (149, 2048)\n",
      "Extracted features for sequence '08xgGFk5fds_905_915': (249, 2048)\n",
      "Extracted features for sequence '0BHL32Bw70E_221_227': (150, 2048)\n",
      "Extracted features for sequence '0BHL32Bw70E_95_104': (224, 2048)\n",
      "Extracted features for sequence '0dnkuv1CF9M_211_238': (647, 2048)\n",
      "Extracted features for sequence '0fTU-1BX8xk_71_109': (1138, 2048)\n",
      "Extracted features for sequence '0TCfRnb1AiM_191_206': (448, 2048)\n",
      "Extracted features for sequence '0TCfRnb1AiM_36_46': (299, 2048)\n",
      "Extracted features for sequence '0TCfRnb1AiM_99_110': (329, 2048)\n",
      "Extracted features for sequence '0TUKi6_pv_E_356_367': (330, 2048)\n",
      "Extracted features for sequence '0Xtp77A4zF4_344_448': (3117, 2048)\n",
      "Extracted features for sequence '0Xtp77A4zF4_449_515': (1978, 2048)\n",
      "Extracted features for sequence '0Xtp77A4zF4_8_84': (2277, 2048)\n",
      "Extracted features for sequence '0Z2O6K1GiQk_117_133': (479, 2048)\n",
      "Extracted features for sequence '13VxOmABU_0_434_445': (274, 2048)\n",
      "Extracted features for sequence '13VxOmABU_0_70_82': (299, 2048)\n",
      "Extracted features for sequence '13VxOmABU_0_98_104': (149, 2048)\n",
      "Extracted features for sequence '18BUf9jXR34_51_58': (167, 2048)\n",
      "Extracted features for sequence '18BUf9jXR34_59_73': (335, 2048)\n",
      "Extracted features for sequence '18BUf9jXR34_74_87': (310, 2048)\n",
      "Extracted features for sequence '18BUf9jXR34_88_98': (239, 2048)\n",
      "Extracted features for sequence '18BUf9jXR34_99_154': (1318, 2048)\n",
      "Extracted features for sequence '1alMJSJT_NQ_192_215': (689, 2048)\n",
      "Extracted features for sequence '1B7D6kASN5I_9_14': (125, 2048)\n",
      "Extracted features for sequence '1HPruyf3MAE_204_211': (209, 2048)\n",
      "Extracted features for sequence '1HPruyf3MAE_256_267': (328, 2048)\n",
      "Extracted features for sequence '1HPruyf3MAE_472_491': (569, 2048)\n",
      "Extracted features for sequence '1HwwIdnpTMY_453_460': (167, 2048)\n",
      "Extracted features for sequence '1ifHYTW_AU0_105_112': (209, 2048)\n",
      "Extracted features for sequence '1ifHYTW_AU0_113_126': (389, 2048)\n",
      "Extracted features for sequence '1ifHYTW_AU0_146_152': (180, 2048)\n",
      "Extracted features for sequence '1ifHYTW_AU0_269_275': (180, 2048)\n",
      "Extracted features for sequence '1ifHYTW_AU0_282_288': (179, 2048)\n",
      "Extracted features for sequence '1ifHYTW_AU0_334_344': (299, 2048)\n",
      "Extracted features for sequence '1ifHYTW_AU0_366_371': (151, 2048)\n",
      "Extracted features for sequence '1ifHYTW_AU0_444_455': (330, 2048)\n",
      "Extracted features for sequence '1ifHYTW_AU0_577_583': (179, 2048)\n",
      "Extracted features for sequence '1ifHYTW_AU0_674_680': (181, 2048)\n",
      "Extracted features for sequence '1ifHYTW_AU0_681_690': (269, 2048)\n",
      "Extracted features for sequence '1ifHYTW_AU0_727_732': (149, 2048)\n",
      "Extracted features for sequence '1ifHYTW_AU0_764_770': (179, 2048)\n",
      "Extracted features for sequence '1ifHYTW_AU0_88_95': (210, 2048)\n",
      "Extracted features for sequence '1iny6gC63-0_38_45': (174, 2048)\n",
      "Extracted features for sequence '1k9qcUaw_ZY_92_106': (418, 2048)\n",
      "Extracted features for sequence '1qXblBx-Ikc_117_176': (1769, 2048)\n",
      "Extracted features for sequence '1qXblBx-Ikc_198_224': (779, 2048)\n",
      "Extracted features for sequence '1SoLeD-rU_k_332_340': (191, 2048)\n",
      "Extracted features for sequence '1SoLeD-rU_k_341_348': (167, 2048)\n",
      "Extracted features for sequence '1W6WCPBSR_s_38_44': (180, 2048)\n",
      "Extracted features for sequence '1W6WCPBSR_s_45_54': (270, 2048)\n",
      "Extracted features for sequence '1W6WCPBSR_s_55_64': (270, 2048)\n",
      "Extracted features for sequence '1W6WCPBSR_s_86_93': (210, 2048)\n",
      "Extracted features for sequence '1W6WCPBSR_s_94_105': (328, 2048)\n",
      "Extracted features for sequence '24k9Q4dPBg8_548_564': (399, 2048)\n",
      "Extracted features for sequence '28klGNDvFVA_12_44': (958, 2048)\n",
      "Extracted features for sequence '2DiQUX11YaY_12_20': (200, 2048)\n",
      "Extracted features for sequence '2DiQUX11YaY_188_202': (349, 2048)\n",
      "Extracted features for sequence '2DiQUX11YaY_218_226': (199, 2048)\n",
      "Extracted features for sequence '2DiQUX11YaY_26_39': (324, 2048)\n",
      "Extracted features for sequence '2DiQUX11YaY_272_279': (174, 2048)\n",
      "Extracted features for sequence '2DiQUX11YaY_40_47': (174, 2048)\n",
      "Extracted features for sequence '2DiQUX11YaY_4_11': (174, 2048)\n",
      "Extracted features for sequence '2DiQUX11YaY_92_100': (199, 2048)\n",
      "Extracted features for sequence '2iXfqNZ7hAQ_0_45': (1348, 2048)\n",
      "Extracted features for sequence '2KQPgcYYDc4_107_118': (274, 2048)\n",
      "Extracted features for sequence '2l5-sry-rWg_312_318': (179, 2048)\n",
      "Extracted features for sequence '2l5-sry-rWg_322_329': (210, 2048)\n",
      "Extracted features for sequence '2l5-sry-rWg_338_344': (179, 2048)\n",
      "Extracted features for sequence '2Lze_h4_VXA_544_588': (1054, 2048)\n",
      "Extracted features for sequence '2Lze_h4_VXA_589_600': (263, 2048)\n",
      "Extracted features for sequence '2Lze_h4_VXA_75_96': (502, 2048)\n",
      "Extracted features for sequence '2V_rJpY4BZc_192_201': (215, 2048)\n",
      "Extracted features for sequence '2ZcIrGekeNU_1231_1242': (328, 2048)\n",
      "Extracted features for sequence '2ZcIrGekeNU_350_363': (389, 2048)\n",
      "Extracted features for sequence '2ZcIrGekeNU_625_635': (298, 2048)\n",
      "Extracted features for sequence '2ZcIrGekeNU_662_669': (209, 2048)\n",
      "Extracted features for sequence '2_tnrvMIt2E_35_41': (149, 2048)\n",
      "Extracted features for sequence '2_tnrvMIt2E_42_55': (324, 2048)\n",
      "Extracted features for sequence '2_tnrvMIt2E_99_135': (900, 2048)\n",
      "Extracted features for sequence '3EUKTcGspIQ_282_305': (551, 2048)\n",
      "Extracted features for sequence '3EUKTcGspIQ_312_321': (215, 2048)\n",
      "Extracted features for sequence '3kgPCiPtpzg_119_131': (299, 2048)\n",
      "Extracted features for sequence '3kgPCiPtpzg_245_256': (274, 2048)\n",
      "Extracted features for sequence '3kgPCiPtpzg_311_321': (249, 2048)\n",
      "Extracted features for sequence '3kgPCiPtpzg_32_49': (424, 2048)\n",
      "Extracted features for sequence '3kgPCiPtpzg_335_349': (349, 2048)\n",
      "Extracted features for sequence '3kgPCiPtpzg_357_371': (349, 2048)\n",
      "Extracted features for sequence '3LQ8elG8Q0M_453_463': (250, 2048)\n",
      "Extracted features for sequence '3nk01iQPL1s_114_123': (215, 2048)\n",
      "Extracted features for sequence '3nk01iQPL1s_84_91': (167, 2048)\n",
      "Extracted features for sequence '3NNyX76PV1o_130_139': (224, 2048)\n",
      "Extracted features for sequence '3NNyX76PV1o_198_203': (125, 2048)\n",
      "Extracted features for sequence '3NNyX76PV1o_272_277': (125, 2048)\n",
      "Extracted features for sequence '3NNyX76PV1o_449_454': (124, 2048)\n",
      "Extracted features for sequence '3NNyX76PV1o_467_472': (125, 2048)\n",
      "Extracted features for sequence '3NNyX76PV1o_637_652': (374, 2048)\n",
      "Extracted features for sequence '3NNyX76PV1o_69_75': (149, 2048)\n",
      "Extracted features for sequence '3NNyX76PV1o_729_734': (125, 2048)\n",
      "Extracted features for sequence '3Tr4-Ggmric_149_163': (419, 2048)\n",
      "Extracted features for sequence '3Tr4-Ggmric_168_181': (390, 2048)\n",
      "Extracted features for sequence '3Tr4-Ggmric_193_208': (449, 2048)\n",
      "Extracted features for sequence '3Tr4-Ggmric_214_233': (569, 2048)\n",
      "Extracted features for sequence '3Tr4-Ggmric_64_74': (299, 2048)\n",
      "Extracted features for sequence '3tuMRFJ45Ok_8_25': (424, 2048)\n",
      "Extracted features for sequence '4271ylBgArU_38_45': (174, 2048)\n",
      "Extracted features for sequence '4271ylBgArU_62_71': (224, 2048)\n",
      "Extracted features for sequence '42Xl_83ouMk_10_26': (399, 2048)\n",
      "Extracted features for sequence '43EYzm0-H1M_82_132': (1498, 2048)\n",
      "Extracted features for sequence '44Ej5SimL7w_163_208': (1345, 2048)\n",
      "Extracted features for sequence '4AKKHZsrjgo_80_92': (299, 2048)\n",
      "Extracted features for sequence '4CI-3geDR58_142_161': (474, 2048)\n",
      "Extracted features for sequence '4cSMt4FB6wM_165_173': (239, 2048)\n",
      "Extracted features for sequence '4eWnWSX8dIk_70_81': (328, 2048)\n",
      "Extracted features for sequence '4fDe9f3cclA_167_173': (150, 2048)\n",
      "Extracted features for sequence '4fDe9f3cclA_263_271': (199, 2048)\n",
      "Extracted features for sequence '4fDe9f3cclA_362_370': (199, 2048)\n",
      "Extracted features for sequence '4fDe9f3cclA_456_461': (125, 2048)\n",
      "Extracted features for sequence '4iaWpLXPwWk_20_26': (143, 2048)\n",
      "Extracted features for sequence '4LFwzgwRyrY_12_18': (179, 2048)\n",
      "Extracted features for sequence '4LFwzgwRyrY_135_141': (180, 2048)\n",
      "Extracted features for sequence '4LFwzgwRyrY_265_311': (1379, 2048)\n",
      "Extracted features for sequence '4LFwzgwRyrY_312_351': (1169, 2048)\n",
      "Extracted features for sequence '4LFwzgwRyrY_352_378': (779, 2048)\n",
      "Extracted features for sequence '4LFwzgwRyrY_379_396': (509, 2048)\n",
      "Extracted features for sequence '4LFwzgwRyrY_397_404': (209, 2048)\n",
      "Extracted features for sequence '4LFwzgwRyrY_76_114': (1139, 2048)\n",
      "Extracted features for sequence '4MeUoSBckKE_37_45': (239, 2048)\n",
      "Extracted features for sequence '4MHIpuvf4kM_42_50': (239, 2048)\n",
      "Extracted features for sequence '4mXdwU860pI_109_161': (1558, 2048)\n",
      "Extracted features for sequence '4mXdwU860pI_162_189': (808, 2048)\n",
      "Extracted features for sequence '4mXdwU860pI_87_102': (448, 2048)\n",
      "Extracted features for sequence '4nK7qLS7Iq8_0_43': (1073, 2048)\n",
      "Extracted features for sequence '4qJqyOWY8Q4_0_16': (382, 2048)\n",
      "Extracted features for sequence '4t2V806b_WE_333_426': (2787, 2048)\n",
      "Extracted features for sequence '4vOMK0uGiq8_1405_1412': (209, 2048)\n",
      "Extracted features for sequence '54khTg3GHyc_29_37': (199, 2048)\n",
      "Extracted features for sequence '5Ada0XkOuNQ_0_88': (2638, 2048)\n",
      "Extracted features for sequence '5C-9za0J0mE_190_211': (628, 2048)\n",
      "Extracted features for sequence '5C-9za0J0mE_254_264': (299, 2048)\n",
      "Extracted features for sequence '5Exh_P65m54_211_220': (215, 2048)\n",
      "Extracted features for sequence '5Exh_P65m54_231_243': (287, 2048)\n",
      "Extracted features for sequence '5Exh_P65m54_273_279': (144, 2048)\n",
      "Extracted features for sequence '5ff_uLoEBEo_125_133': (200, 2048)\n",
      "Extracted features for sequence '5ff_uLoEBEo_42_55': (324, 2048)\n",
      "Extracted features for sequence '5fhJSO5al8o_727_847': (2999, 2048)\n",
      "Extracted features for sequence '5L4RqKd9MrU_6_12': (150, 2048)\n",
      "Extracted features for sequence '5MdcbbQEglI_363_381': (448, 2048)\n",
      "Extracted features for sequence '5RGiVwM2m18_109_115': (150, 2048)\n",
      "Extracted features for sequence '5RGiVwM2m18_149_155': (149, 2048)\n",
      "Extracted features for sequence '5RGiVwM2m18_18_24': (149, 2048)\n",
      "Extracted features for sequence '5RGiVwM2m18_70_76': (149, 2048)\n",
      "Extracted features for sequence '5wTgVHTMDNY_309_324': (449, 2048)\n",
      "Extracted features for sequence '5Yfx40Hz95I_39_67': (671, 2048)\n",
      "Extracted features for sequence '5_Zc9mFPTV8_38_74': (1078, 2048)\n",
      "Extracted features for sequence '5_Zc9mFPTV8_75_124': (1468, 2048)\n",
      "Extracted features for sequence '5_Zc9mFPTV8_7_37': (898, 2048)\n",
      "Extracted features for sequence '66iVMyHk9bw_12_21': (269, 2048)\n",
      "Extracted features for sequence '6BI1ltwsloE_0_30': (898, 2048)\n",
      "Extracted features for sequence '6BvXNmxC_F0_234_240': (143, 2048)\n",
      "Extracted features for sequence '6BvXNmxC_F0_275_283': (191, 2048)\n",
      "Extracted features for sequence '6BvXNmxC_F0_303_310': (167, 2048)\n",
      "Extracted features for sequence '6CZXldRSZD8_481_487': (179, 2048)\n",
      "Extracted features for sequence '6dHWDBvkR2g_129_135': (149, 2048)\n",
      "Extracted features for sequence '6dHWDBvkR2g_136_169': (824, 2048)\n",
      "Extracted features for sequence '6dHWDBvkR2g_54_80': (649, 2048)\n",
      "Extracted features for sequence '6dHWDBvkR2g_81_95': (349, 2048)\n",
      "Extracted features for sequence '6dHWDBvkR2g_96_128': (799, 2048)\n",
      "Extracted features for sequence '6EWOHAs2CeY_116_127': (329, 2048)\n",
      "Extracted features for sequence '6HQ08vnchIU_0_33': (988, 2048)\n",
      "Extracted features for sequence '6jTqT_Ucg6Q_76_92': (478, 2048)\n",
      "Extracted features for sequence '6TgrueI-L_E_256_262': (179, 2048)\n",
      "Extracted features for sequence '6tXN9qePKNA_682_688': (149, 2048)\n",
      "Extracted features for sequence '6XaKLILT7iE_132_141': (269, 2048)\n",
      "Extracted features for sequence '6zk5L6WxAXc_164_180': (479, 2048)\n",
      "Extracted features for sequence '6zk5L6WxAXc_181_220': (1168, 2048)\n",
      "Extracted features for sequence '6zk5L6WxAXc_297_387': (2696, 2048)\n",
      "Extracted features for sequence '720lf_07rgo_129_135': (149, 2048)\n",
      "Extracted features for sequence '720lf_07rgo_15_26': (274, 2048)\n",
      "Extracted features for sequence '720lf_07rgo_32_51': (474, 2048)\n",
      "Extracted features for sequence '720lf_07rgo_74_123': (1224, 2048)\n",
      "Extracted features for sequence '74PQL3Qt6RI_0_35': (873, 2048)\n",
      "Extracted features for sequence '7F2TseXDyOg_0_20': (598, 2048)\n",
      "Extracted features for sequence '7GVetqf5198_147_157': (239, 2048)\n",
      "Extracted features for sequence '7GVetqf5198_440_449': (215, 2048)\n",
      "Extracted features for sequence '7GVetqf5198_466_476': (239, 2048)\n",
      "Extracted features for sequence '7hvxfSsodlM_6_13': (167, 2048)\n",
      "Extracted features for sequence '7KUPAZCXrvo_0_66': (1977, 2048)\n",
      "Extracted features for sequence '7s-99QVpr0M_314_321': (167, 2048)\n",
      "Extracted features for sequence '7s-99QVpr0M_372_378': (143, 2048)\n",
      "Extracted features for sequence '7s-99QVpr0M_543_553': (239, 2048)\n",
      "Extracted features for sequence '7sBRE6MY1p8_0_79': (2368, 2048)\n",
      "Extracted features for sequence '7tz19k-y-vQ_131_140': (269, 2048)\n",
      "Extracted features for sequence '7tz19k-y-vQ_184_191': (209, 2048)\n",
      "Extracted features for sequence '7xnB39oUqfI_300_420': (2998, 2048)\n",
      "Extracted features for sequence '7xnB39oUqfI_438_446': (199, 2048)\n",
      "Extracted features for sequence '7yxJ1M4aK_w_39_53': (349, 2048)\n",
      "Extracted features for sequence '7zXOvVzflCA_205_214': (269, 2048)\n",
      "Extracted features for sequence '81ahuidFUWw_430_465': (1047, 2048)\n",
      "Extracted features for sequence '81ahuidFUWw_799_818': (568, 2048)\n",
      "Extracted features for sequence '81ahuidFUWw_838_873': (1047, 2048)\n",
      "Extracted features for sequence '81ahuidFUWw_909_919': (298, 2048)\n",
      "Extracted features for sequence '85oisikAKOI_494_537': (1285, 2048)\n",
      "Extracted features for sequence '881uK5SDnFU_26_55': (868, 2048)\n",
      "Extracted features for sequence '881uK5SDnFU_56_83': (810, 2048)\n",
      "Extracted features for sequence '881uK5SDnFU_84_119': (1048, 2048)\n",
      "Extracted features for sequence '8BQ-nVvJJMQ_125_143': (449, 2048)\n",
      "Extracted features for sequence '8BQ-nVvJJMQ_144_164': (499, 2048)\n",
      "Extracted features for sequence '8BQ-nVvJJMQ_165_187': (549, 2048)\n",
      "Extracted features for sequence '8BQ-nVvJJMQ_6_59': (1324, 2048)\n",
      "Extracted features for sequence '8emfOel6ZZM_392_406': (349, 2048)\n",
      "Extracted features for sequence '8H_DSErYUZk_76_81': (119, 2048)\n",
      "Extracted features for sequence '8lsYuDsor08_104_111': (174, 2048)\n",
      "Extracted features for sequence '8M1_6RWFxtY_0_29': (868, 2048)\n",
      "Extracted features for sequence '8VCdF6fxOFk_145_218': (1824, 2048)\n",
      "Extracted features for sequence '8xU5GZFVEd0_0_15': (358, 2048)\n",
      "Extracted features for sequence '934Befj4aD8_370_375': (124, 2048)\n",
      "Extracted features for sequence '9iBjqAmNiJA_379_420': (1228, 2048)\n",
      "Extracted features for sequence '9iBjqAmNiJA_422_428': (179, 2048)\n",
      "Extracted features for sequence '9OIAgiB8rac_106_116': (249, 2048)\n",
      "Extracted features for sequence '9OIAgiB8rac_242_268': (649, 2048)\n",
      "Extracted features for sequence '9OIAgiB8rac_98_105': (174, 2048)\n",
      "Extracted features for sequence '9q7R9qFcrbI_102_112': (240, 2048)\n",
      "Extracted features for sequence '9q7R9qFcrbI_158_175': (406, 2048)\n",
      "Extracted features for sequence '9q7R9qFcrbI_30_36': (144, 2048)\n",
      "Extracted features for sequence '9q7R9qFcrbI_39_50': (263, 2048)\n",
      "Extracted features for sequence '9q7R9qFcrbI_56_77': (503, 2048)\n",
      "Extracted features for sequence '9q7R9qFcrbI_90_100': (240, 2048)\n",
      "Extracted features for sequence '9s2tAsyTFsw_79_91': (359, 2048)\n",
      "Extracted features for sequence '9xr9SBPnb58_32_61': (694, 2048)\n",
      "Extracted features for sequence '9YaFR5-MUPQ_151_180': (695, 2048)\n",
      "Extracted features for sequence '9YaFR5-MUPQ_54_69': (359, 2048)\n",
      "Extracted features for sequence '9Z-0GremE6g_0_68': (2036, 2048)\n",
      "Extracted features for sequence '9Zs3YvVBPvI_11_19': (199, 2048)\n",
      "Extracted features for sequence 'A1Kc286gTGU_18_32': (349, 2048)\n",
      "Extracted features for sequence 'aEBejHvkYtg_189_200': (330, 2048)\n",
      "Extracted features for sequence 'aEBejHvkYtg_20_25': (149, 2048)\n",
      "Extracted features for sequence 'aEBejHvkYtg_72_77': (149, 2048)\n",
      "Extracted features for sequence 'AFigIK6zwvc_170_191': (629, 2048)\n",
      "Extracted features for sequence 'AFigIK6zwvc_24_31': (209, 2048)\n",
      "Extracted features for sequence 'AFigIK6zwvc_67_84': (509, 2048)\n",
      "Extracted features for sequence 'AFsdQDKd2ek_1033_1043': (299, 2048)\n",
      "Extracted features for sequence 'aHT6gKyNTp8_0_8': (238, 2048)\n",
      "Extracted features for sequence 'aHT6gKyNTp8_248_254': (179, 2048)\n",
      "Extracted features for sequence 'aHT6gKyNTp8_77_90': (389, 2048)\n",
      "Extracted features for sequence 'aiu5vERlUT4_215_229': (349, 2048)\n",
      "Extracted features for sequence 'Arh3ms6skIA_105_116': (263, 2048)\n",
      "Extracted features for sequence 'Arh3ms6skIA_121_138': (407, 2048)\n",
      "Extracted features for sequence 'Arh3ms6skIA_157_166': (215, 2048)\n",
      "Extracted features for sequence 'Arh3ms6skIA_296_302': (143, 2048)\n",
      "Extracted features for sequence 'Arh3ms6skIA_84_101': (409, 2048)\n",
      "Extracted features for sequence 'AStqdbLvQqs_0_20': (588, 2048)\n",
      "Extracted features for sequence 'ATj6Z89B680_61_70': (268, 2048)\n",
      "Extracted features for sequence 'ay7mKcpXQ6s_87_98': (263, 2048)\n",
      "Extracted features for sequence 'b6UyrHBJTKk_0_12': (286, 2048)\n",
      "Extracted features for sequence 'B7IZK2fO9m0_0_30': (898, 2048)\n",
      "Extracted features for sequence 'BaKPkrpKYI8_103_110': (210, 2048)\n",
      "Extracted features for sequence 'BaKPkrpKYI8_159_165': (179, 2048)\n",
      "Extracted features for sequence 'BjI79UzSsL4_0_32': (948, 2048)\n",
      "Extracted features for sequence 'BJLUd_rjMQg_374_380': (179, 2048)\n",
      "Extracted features for sequence 'BJLUd_rjMQg_388_394': (179, 2048)\n",
      "Extracted features for sequence 'BOi79Zuj8Jk_140_151': (263, 2048)\n",
      "Extracted features for sequence 'BOi79Zuj8Jk_287_295': (191, 2048)\n",
      "Extracted features for sequence 'Bqn_GzsrDqM_174_182': (191, 2048)\n",
      "Extracted features for sequence 'Bqn_GzsrDqM_67_74': (167, 2048)\n",
      "Extracted features for sequence 'BsqM8UWNiNo_107_120': (324, 2048)\n",
      "Extracted features for sequence 'BsqM8UWNiNo_138_148': (249, 2048)\n",
      "Extracted features for sequence 'BsqM8UWNiNo_151_166': (374, 2048)\n",
      "Extracted features for sequence 'BsqM8UWNiNo_18_40': (549, 2048)\n",
      "Extracted features for sequence 'BsqM8UWNiNo_53_59': (149, 2048)\n",
      "Extracted features for sequence 'BsqM8UWNiNo_73_82': (224, 2048)\n",
      "Extracted features for sequence 'bum0SKtk6Qw_82_88': (179, 2048)\n",
      "Extracted features for sequence 'Bw_pfRDJ_c4_529_551': (658, 2048)\n",
      "Extracted features for sequence 'BYWAsYayARk_0_19': (568, 2048)\n",
      "Extracted features for sequence 'bZp5U-gwQ5k_213_222': (224, 2048)\n",
      "Extracted features for sequence 'bZysB1KJKGA_176_182': (149, 2048)\n",
      "Extracted features for sequence 'bZysB1KJKGA_183_190': (174, 2048)\n",
      "Extracted features for sequence 'c2ecuoGWjJM_157_167': (299, 2048)\n",
      "Extracted features for sequence 'C85qIzJsFKA_35_45': (249, 2048)\n",
      "Extracted features for sequence 'CaLi7pN0Y2E_138_167': (724, 2048)\n",
      "Extracted features for sequence 'Cc110v8fRnI_106_120': (419, 2048)\n",
      "Extracted features for sequence 'Cc110v8fRnI_147_176': (868, 2048)\n",
      "Extracted features for sequence 'Cc110v8fRnI_180_189': (269, 2048)\n",
      "Extracted features for sequence 'Cc110v8fRnI_201_226': (749, 2048)\n",
      "Extracted features for sequence 'CcevP4Dgocw_55_66': (316, 2048)\n",
      "Extracted features for sequence 'cd9FI5DC0Bg_151_157': (143, 2048)\n",
      "Extracted features for sequence 'cd9FI5DC0Bg_453_468': (359, 2048)\n",
      "Extracted features for sequence 'cHADJkgoYwI_4_21': (509, 2048)\n",
      "Extracted features for sequence 'ci9uoC7fwJ0_13_29': (383, 2048)\n",
      "Extracted features for sequence 'CIejCqpSzIE_35_47': (360, 2048)\n",
      "Extracted features for sequence 'CIejCqpSzIE_57_69': (360, 2048)\n",
      "Extracted features for sequence 'cIiTdsvCjYo_126_132': (179, 2048)\n",
      "Extracted features for sequence 'cIiTdsvCjYo_64_71': (209, 2048)\n",
      "Extracted features for sequence 'Cioa-jes2Ls_885_909': (599, 2048)\n",
      "Extracted features for sequence 'Cn8PiqIXEjQ_107_117': (299, 2048)\n",
      "Extracted features for sequence 'Cn8PiqIXEjQ_139_157': (539, 2048)\n",
      "Extracted features for sequence 'Cn8PiqIXEjQ_158_169': (328, 2048)\n",
      "Extracted features for sequence 'Cn8PiqIXEjQ_34_44': (299, 2048)\n",
      "Extracted features for sequence 'Cp8UtHUvn8g_0_38': (1138, 2048)\n",
      "Extracted features for sequence 'CqusBYOcaA4_437_448': (274, 2048)\n",
      "Extracted features for sequence 'CqusBYOcaA4_639_647': (199, 2048)\n",
      "Extracted features for sequence 'CtksAvk6myU_0_10': (248, 2048)\n",
      "Extracted features for sequence 'cuDL7PXKVMI_101_108': (174, 2048)\n",
      "Extracted features for sequence 'd2B2tV8gxtI_136_150': (349, 2048)\n",
      "Extracted features for sequence 'd2B2tV8gxtI_186_194': (199, 2048)\n",
      "Extracted features for sequence 'd2B2tV8gxtI_279_292': (324, 2048)\n",
      "Extracted features for sequence 'd2B2tV8gxtI_28_38': (249, 2048)\n",
      "Extracted features for sequence 'd7BW62RApU4_131_139': (191, 2048)\n",
      "Extracted features for sequence 'd7BW62RApU4_91_99': (191, 2048)\n",
      "Extracted features for sequence 'D8RppPVMWAM_0_18': (448, 2048)\n",
      "Extracted features for sequence 'D9W-KQmzi9Y_384_391': (173, 2048)\n",
      "Extracted features for sequence 'DFnWIxePOH8_527_537': (249, 2048)\n",
      "Extracted features for sequence 'dhBkWdeLHFQ_115_124': (269, 2048)\n",
      "Extracted features for sequence 'DNQFsRk5kW0_41_54': (389, 2048)\n",
      "Extracted features for sequence 'DOmSEGVuYAg_0_31': (742, 2048)\n",
      "Extracted features for sequence 'DOmSEGVuYAg_300_335': (838, 2048)\n",
      "Extracted features for sequence 'DOmSEGVuYAg_348_355': (167, 2048)\n",
      "Extracted features for sequence 'DOmSEGVuYAg_384_400': (383, 2048)\n",
      "Extracted features for sequence 'DOmSEGVuYAg_505_518': (311, 2048)\n",
      "Extracted features for sequence 'DpQSyrMgfpg_217_229': (359, 2048)\n",
      "Extracted features for sequence 'Dps2_fUosJo_0_40': (998, 2048)\n",
      "Extracted features for sequence 'Dps2_fUosJo_278_302': (599, 2048)\n",
      "Extracted features for sequence 'Dr9NRApKGJY_615_626': (329, 2048)\n",
      "Extracted features for sequence 'DV6xCdLpUmI_109_116': (210, 2048)\n",
      "Extracted features for sequence 'DV6xCdLpUmI_129_141': (358, 2048)\n",
      "Extracted features for sequence 'DV6xCdLpUmI_27_42': (448, 2048)\n",
      "Extracted features for sequence 'DV6xCdLpUmI_65_92': (809, 2048)\n",
      "Extracted features for sequence 'DWNuyUYB-jA_17_22': (124, 2048)\n",
      "Extracted features for sequence 'dxkYPpcsX9A_77_82': (120, 2048)\n",
      "Extracted features for sequence 'E-hyDICaWrQ_991_1009': (449, 2048)\n",
      "Extracted features for sequence 'e09Ig7lkxGs_258_270': (359, 2048)\n",
      "Extracted features for sequence 'E2BQNNwf6pA_2870_2880': (299, 2048)\n",
      "Extracted features for sequence 'earxxPKwFyg_31_42': (274, 2048)\n",
      "Extracted features for sequence 'earxxPKwFyg_54_65': (274, 2048)\n",
      "Extracted features for sequence 'earxxPKwFyg_96_107': (274, 2048)\n",
      "Extracted features for sequence 'EedFxiJJAMI_28_43': (449, 2048)\n",
      "Extracted features for sequence 'EedFxiJJAMI_62_76': (418, 2048)\n",
      "Extracted features for sequence 'EedFxiJJAMI_90_100': (299, 2048)\n",
      "Extracted features for sequence 'EGadMYDlCkI_10_23': (324, 2048)\n",
      "Extracted features for sequence 'eiGpNqHGw00_0_6': (178, 2048)\n",
      "Extracted features for sequence 'EjekbTQT2dw_129_155': (778, 2048)\n",
      "Extracted features for sequence 'Eq3QI54Mrno_28_36': (199, 2048)\n",
      "Extracted features for sequence 'eUcznRvP2Uw_0_16': (478, 2048)\n",
      "Extracted features for sequence 'Ext8wbSqJbs_132_161': (869, 2048)\n",
      "Extracted features for sequence 'Ez46D_sDg5w_121_132': (328, 2048)\n",
      "Extracted features for sequence 'F-51y-KFoiM_113_135': (549, 2048)\n",
      "Extracted features for sequence 'F-51y-KFoiM_299_320': (524, 2048)\n",
      "Extracted features for sequence 'F-51y-KFoiM_355_378': (574, 2048)\n",
      "Extracted features for sequence 'F-51y-KFoiM_36_55': (474, 2048)\n",
      "Extracted features for sequence 'f0lg_xnL4rg_126_134': (199, 2048)\n",
      "Extracted features for sequence 'F1drpxkXeNo_179_204': (624, 2048)\n",
      "Extracted features for sequence 'F4Jna44266A_46_52': (179, 2048)\n",
      "Extracted features for sequence 'fcyDTBjfL0o_112_122': (249, 2048)\n",
      "Extracted features for sequence 'fcyDTBjfL0o_191_201': (249, 2048)\n",
      "Extracted features for sequence 'fDjt6EVHq4E_0_8': (238, 2048)\n",
      "Extracted features for sequence 'fDjt6EVHq4E_44_58': (419, 2048)\n",
      "Extracted features for sequence 'fGJAm1iM1Vc_28_37': (215, 2048)\n",
      "Extracted features for sequence 'fGJAm1iM1Vc_87_96': (215, 2048)\n",
      "Extracted features for sequence 'FgWn75B0SPs_162_168': (142, 2048)\n",
      "Extracted features for sequence 'FHteFxMUToQ_273_291': (539, 2048)\n",
      "Extracted features for sequence 'FIMd5KFG1vQ_22_29': (174, 2048)\n",
      "Extracted features for sequence 'FIMd5KFG1vQ_268_292': (599, 2048)\n",
      "Extracted features for sequence 'FIMd5KFG1vQ_9_17': (199, 2048)\n",
      "Extracted features for sequence 'FL0qDVatFgk_246_259': (389, 2048)\n",
      "Extracted features for sequence 'FL0qDVatFgk_362_389': (808, 2048)\n",
      "Extracted features for sequence 'fl3k3Z3Tin4_12_17': (150, 2048)\n",
      "Extracted features for sequence 'fl3k3Z3Tin4_42_51': (269, 2048)\n",
      "Extracted features for sequence 'FQD5j4xeR8g_0_9': (223, 2048)\n",
      "Extracted features for sequence 'FQD5j4xeR8g_22_36': (349, 2048)\n",
      "Extracted features for sequence 'FQD5j4xeR8g_37_43': (150, 2048)\n",
      "Extracted features for sequence 'FuCNH7dqZxg_298_322': (576, 2048)\n",
      "Extracted features for sequence 'FuCNH7dqZxg_323_330': (167, 2048)\n",
      "Extracted features for sequence 'FW4vBcixJn4_0_15': (359, 2048)\n",
      "Extracted features for sequence 'G-_OBm_gw3c_634_641': (208, 2048)\n",
      "Extracted features for sequence 'G6zWzT_PLq4_51_65': (349, 2048)\n",
      "Extracted features for sequence 'GA6_pzGCioM_82_104': (658, 2048)\n",
      "Extracted features for sequence 'GD-0leFOllI_630_641': (328, 2048)\n",
      "Extracted features for sequence 'GD-0leFOllI_768_777': (269, 2048)\n",
      "Extracted features for sequence 'GgL_D4Xasaw_527_535': (191, 2048)\n",
      "Extracted features for sequence 'GHkt7tYwVwY_192_206': (418, 2048)\n",
      "Extracted features for sequence 'gis-qotycU8_227_235': (191, 2048)\n",
      "Extracted features for sequence 'glGvYiDWe-w_623_630': (167, 2048)\n",
      "Extracted features for sequence 'GLzsVzXtyH0_22_35': (389, 2048)\n",
      "Extracted features for sequence 'GLzsVzXtyH0_8_20': (359, 2048)\n",
      "Extracted features for sequence 'gnhfKhdTahI_0_7': (208, 2048)\n",
      "Extracted features for sequence 'gnhfKhdTahI_8_20': (358, 2048)\n",
      "Extracted features for sequence 'gol8Eek9VcE_142_151': (215, 2048)\n",
      "Extracted features for sequence 'gol8Eek9VcE_153_163': (239, 2048)\n",
      "Extracted features for sequence 'GSVtaMT5j2A_443_458': (449, 2048)\n",
      "Extracted features for sequence 'GsXOB9nJZI8_3_35': (958, 2048)\n",
      "Extracted features for sequence 'Gt1AWwtSqTU_155_162': (209, 2048)\n",
      "Extracted features for sequence 'GTk9evsaPW4_0_14': (418, 2048)\n",
      "Extracted features for sequence 'GV6F_cai_Vo_96_123': (808, 2048)\n",
      "Extracted features for sequence 'GXAOz9azkNg_143_151': (240, 2048)\n",
      "Extracted features for sequence 'gyE0Owe-WL4_109_122': (324, 2048)\n",
      "Extracted features for sequence 'gyE0Owe-WL4_127_133': (150, 2048)\n",
      "Extracted features for sequence 'GZQUV46bHVk_97_116': (569, 2048)\n",
      "Extracted features for sequence 'h2CFY6J8aiE_481_488': (174, 2048)\n",
      "Extracted features for sequence 'h2hwIDQkzBE_12_27': (375, 2048)\n",
      "Extracted features for sequence 'h2hwIDQkzBE_216_229': (324, 2048)\n",
      "Extracted features for sequence 'h2hwIDQkzBE_87_92': (125, 2048)\n",
      "Extracted features for sequence 'HbTzL6BPTqQ_73_87': (419, 2048)\n",
      "Extracted features for sequence 'HCucos4qGQw_193_203': (249, 2048)\n",
      "Extracted features for sequence 'HCucos4qGQw_36_52': (399, 2048)\n",
      "Extracted features for sequence 'HCucos4qGQw_60_68': (199, 2048)\n",
      "Extracted features for sequence 'HDNOB6TnHSI_4_12': (239, 2048)\n",
      "Extracted features for sequence 'hHKJruybYgQ_46_62': (479, 2048)\n",
      "Extracted features for sequence 'hNMvxvvC_z0_281_288': (209, 2048)\n",
      "Extracted features for sequence 'HoycHBRtUl8_0_19': (473, 2048)\n",
      "Extracted features for sequence 'HucUxlgXutk_0_34': (1017, 2048)\n",
      "Extracted features for sequence 'HUWJl13C0dQ_104_118': (419, 2048)\n",
      "Extracted features for sequence 'HUWJl13C0dQ_164_191': (809, 2048)\n",
      "Extracted features for sequence 'HzOiJ87yNIg_206_233': (809, 2048)\n",
      "Extracted features for sequence 'HzOiJ87yNIg_20_44': (719, 2048)\n",
      "Extracted features for sequence 'HzOiJ87yNIg_237_262': (749, 2048)\n",
      "Extracted features for sequence 'I1hPndGcir4_73_106': (988, 2048)\n",
      "Extracted features for sequence 'i2c_oY7J4J4_0_10': (248, 2048)\n",
      "Extracted features for sequence 'i2c_oY7J4J4_23_29': (149, 2048)\n",
      "Extracted features for sequence 'i2c_oY7J4J4_78_85': (174, 2048)\n",
      "Extracted features for sequence 'I53PaTMsXbQ_244_250': (149, 2048)\n",
      "Extracted features for sequence 'i63DxymZp-0_1_7': (149, 2048)\n",
      "Extracted features for sequence 'i85kpkUSTfM_0_14': (335, 2048)\n",
      "Extracted features for sequence 'If7eg3vAKpE_24_64': (1198, 2048)\n",
      "Extracted features for sequence 'If7eg3vAKpE_65_84': (569, 2048)\n",
      "Extracted features for sequence 'iSJqd8z1v20_0_13': (388, 2048)\n",
      "Extracted features for sequence 'issQGRCxt3A_281_290': (269, 2048)\n",
      "Extracted features for sequence 'ixZ6iG4Lieg_28_35': (167, 2048)\n",
      "Extracted features for sequence 'J4KLlvQIzfM_212_217': (149, 2048)\n",
      "Extracted features for sequence 'JAaB052VXIs_6_20': (419, 2048)\n",
      "Extracted features for sequence 'JNCYkZxsWUc_659_670': (274, 2048)\n",
      "Extracted features for sequence 'JuuF1Qq7mmY_134_150': (399, 2048)\n",
      "Extracted features for sequence 'jwEJ1ST3vxA_103_110': (209, 2048)\n",
      "Extracted features for sequence 'jwEJ1ST3vxA_209_224': (449, 2048)\n",
      "Extracted features for sequence 'JYq5t0b6F1Y_0_17': (508, 2048)\n",
      "Extracted features for sequence 'K18G2iS4MNU_37_51': (334, 2048)\n",
      "Extracted features for sequence 'k52kVVkQp5A_228_236': (199, 2048)\n",
      "Extracted features for sequence 'K6H9sY6hIeA_146_173': (646, 2048)\n",
      "Extracted features for sequence 'K6H9sY6hIeA_37_54': (406, 2048)\n",
      "Extracted features for sequence 'K6H9sY6hIeA_56_74': (431, 2048)\n",
      "Extracted features for sequence 'K6H9sY6hIeA_79_99': (478, 2048)\n",
      "Extracted features for sequence 'Ka2Heek0PBc_479_490': (263, 2048)\n",
      "Extracted features for sequence 'KauRc4MN-iQ_9_15': (180, 2048)\n",
      "Extracted features for sequence 'KJ5B9LYSm5M_115_126': (262, 2048)\n",
      "Extracted features for sequence 'KJ5B9LYSm5M_39_45': (143, 2048)\n",
      "Extracted features for sequence 'KlB1iSASNqo_143_160': (509, 2048)\n",
      "Extracted features for sequence 'KlB1iSASNqo_76_82': (180, 2048)\n",
      "Extracted features for sequence 'KQqFixbb-o8_120_143': (688, 2048)\n",
      "Extracted features for sequence 'KQqFixbb-o8_144_172': (839, 2048)\n",
      "Extracted features for sequence 'KQqFixbb-o8_173_189': (478, 2048)\n",
      "Extracted features for sequence 'KQqFixbb-o8_17_25': (239, 2048)\n",
      "Extracted features for sequence 'KQqFixbb-o8_242_254': (358, 2048)\n",
      "Extracted features for sequence 'KQqFixbb-o8_26_58': (959, 2048)\n",
      "Extracted features for sequence 'KQqFixbb-o8_276_303': (808, 2048)\n",
      "Extracted features for sequence 'KQqFixbb-o8_90_101': (328, 2048)\n",
      "Extracted features for sequence 'ktm4jIVuXKM_83_95': (358, 2048)\n",
      "Extracted features for sequence 'KxCudfxrdcI_0_13': (388, 2048)\n",
      "Extracted features for sequence 'KxCudfxrdcI_136_148': (359, 2048)\n",
      "Extracted features for sequence 'K_IpzROt3-Y_182_191': (268, 2048)\n",
      "Extracted features for sequence 'L4H-nBgiFmg_113_134': (524, 2048)\n",
      "Extracted features for sequence 'L4H-nBgiFmg_212_226': (349, 2048)\n",
      "Extracted features for sequence 'LC6uhWGDf8E_210_227': (407, 2048)\n",
      "Extracted features for sequence 'LRrkx8cDqWo_135_142': (174, 2048)\n",
      "Extracted features for sequence 'LYuWjliaHqY_824_838': (348, 2048)\n",
      "Extracted features for sequence 'm0N9C4BOf5c_251_263': (287, 2048)\n",
      "Extracted features for sequence 'mDNtTDqfTlY_246_255': (214, 2048)\n",
      "Extracted features for sequence 'MnOzFlfcK3g_26_37': (328, 2048)\n",
      "Extracted features for sequence 'mO9-kPzdECU_524_531': (167, 2048)\n",
      "Extracted features for sequence 'MQg4p2xv1XQ_39_54': (449, 2048)\n",
      "Extracted features for sequence 'Mt89AymlstA_30_48': (538, 2048)\n",
      "Extracted features for sequence 'MuwOOx1Wzfk_16_33': (424, 2048)\n",
      "Extracted features for sequence 'MuwOOx1Wzfk_88_104': (399, 2048)\n",
      "Extracted features for sequence 'MVNPx6_PzuI_0_24': (718, 2048)\n",
      "Extracted features for sequence 'MWplCf4fuKM_180_188': (238, 2048)\n",
      "Extracted features for sequence 'N8GQVqtk028_6_12': (149, 2048)\n",
      "Extracted features for sequence 'N8GQVqtk028_80_86': (150, 2048)\n",
      "Extracted features for sequence 'nnWh8tKfMbk_154_168': (418, 2048)\n",
      "Extracted features for sequence 'Nv1ItNQ8y_g_231_241': (239, 2048)\n",
      "Extracted features for sequence 'NX3QGnK8dGE_104_119': (374, 2048)\n",
      "Extracted features for sequence 'NX3QGnK8dGE_120_135': (374, 2048)\n",
      "Extracted features for sequence 'o1W3jADOA08_179_189': (299, 2048)\n",
      "Extracted features for sequence 'o4xuiPTj3a4_17_31': (349, 2048)\n",
      "Extracted features for sequence 'o61fbnPCYqI_127_134': (208, 2048)\n",
      "Extracted features for sequence 'OabhIVN8Pps_1_22': (629, 2048)\n",
      "Extracted features for sequence 'OjXAmWvL3HY_197_214': (424, 2048)\n",
      "Extracted features for sequence 'OPj9dJRCcug_0_33': (823, 2048)\n",
      "Extracted features for sequence 'OwchMqCYaF4_0_14': (418, 2048)\n",
      "Extracted features for sequence 'OwchMqCYaF4_70_77': (209, 2048)\n",
      "Extracted features for sequence 'P2Kzw86IfQw_0_59': (352, 2048)\n",
      "Extracted features for sequence 'p3sDuX8b8qU_154_160': (149, 2048)\n",
      "Extracted features for sequence 'p3sDuX8b8qU_213_219': (149, 2048)\n",
      "Extracted features for sequence 'p3sDuX8b8qU_85_101': (401, 2048)\n",
      "Extracted features for sequence 'p4MdrvBrXSg_75_81': (143, 2048)\n",
      "Extracted features for sequence 'p4MdrvBrXSg_85_91': (143, 2048)\n",
      "Extracted features for sequence 'p4MdrvBrXSg_94_109': (359, 2048)\n",
      "Extracted features for sequence 'P9DuXLZ6hzY_231_244': (311, 2048)\n",
      "Extracted features for sequence 'pEy6a_PDz1c_30_39': (224, 2048)\n",
      "Extracted features for sequence 'PlPZ-npnGEk_177_196': (568, 2048)\n",
      "Extracted features for sequence 'PLuIRSMK5eo_3_9': (149, 2048)\n",
      "Extracted features for sequence 'pSEdQGGjB8Y_70_78': (199, 2048)\n",
      "Extracted features for sequence 'Q1h0PaJFiXI_21_45': (599, 2048)\n",
      "Extracted features for sequence 'Q2rG9joNzmE_149_156': (173, 2048)\n",
      "Extracted features for sequence 'Q2rG9joNzmE_175_187': (298, 2048)\n",
      "Extracted features for sequence 'Q2rG9joNzmE_367_375': (198, 2048)\n",
      "Extracted features for sequence 'Q2rG9joNzmE_44_58': (348, 2048)\n",
      "Extracted features for sequence 'Q2rG9joNzmE_77_92': (373, 2048)\n",
      "Extracted features for sequence 'Q2rG9joNzmE_93_109': (398, 2048)\n",
      "Extracted features for sequence 'QD25zgSsUiM_400_413': (388, 2048)\n",
      "Extracted features for sequence 'QR6fWfC1Lh0_153_164': (274, 2048)\n",
      "Extracted features for sequence 'qsIaf3jVTxI_0_15': (374, 2048)\n",
      "Extracted features for sequence 'qX6OAWmG6o0_27_41': (335, 2048)\n",
      "Extracted features for sequence 'QzgiCkZLbXw_70_98': (670, 2048)\n",
      "Extracted features for sequence 'R6ggjJ69nOU_21_32': (328, 2048)\n",
      "Extracted features for sequence 'r9yVHYeg9xk_813_819': (149, 2048)\n",
      "Extracted features for sequence 'R9zpXFvEWG4_0_18': (448, 2048)\n",
      "Extracted features for sequence 'rCAUE5iqMeg_173_180': (209, 2048)\n",
      "Extracted features for sequence 'rjIgwHu1HOc_75_85': (299, 2048)\n",
      "Extracted features for sequence 'RmYDQu8RtnM_42_49': (210, 2048)\n",
      "Extracted features for sequence 'Rx-JSwMsfvs_103_111': (199, 2048)\n",
      "Extracted features for sequence 'Ry0Dm6yz8cA_100_110': (299, 2048)\n",
      "Extracted features for sequence 'Ry0Dm6yz8cA_37_49': (359, 2048)\n",
      "Extracted features for sequence 'Ry0Dm6yz8cA_60_73': (388, 2048)\n",
      "Extracted features for sequence 'Ry0Dm6yz8cA_93_99': (179, 2048)\n",
      "Extracted features for sequence 'S8yM3npjwn8_28_39': (274, 2048)\n",
      "Extracted features for sequence 'S8yM3npjwn8_52_62': (249, 2048)\n",
      "Extracted features for sequence 'S8yM3npjwn8_63_79': (399, 2048)\n",
      "Extracted features for sequence 'S9vBXV-tHEM_20_27': (167, 2048)\n",
      "Extracted features for sequence 'S9vBXV-tHEM_223_239': (383, 2048)\n",
      "Extracted features for sequence 'S9vBXV-tHEM_242_261': (454, 2048)\n",
      "Extracted features for sequence 'S9vBXV-tHEM_290_297': (167, 2048)\n",
      "Extracted features for sequence 'SEYuVQ2-ov4_198_204': (179, 2048)\n",
      "Extracted features for sequence 'SEYuVQ2-ov4_388_394': (179, 2048)\n",
      "Extracted features for sequence 'SEYuVQ2-ov4_462_469': (208, 2048)\n",
      "Extracted features for sequence 'SM4dmuL8KKw_13_28': (374, 2048)\n",
      "Extracted features for sequence 'SnrlHsMsG9o_322_329': (209, 2048)\n",
      "Extracted features for sequence 'sPegLaBqB-k_0_6': (178, 2048)\n",
      "Extracted features for sequence 'sPegLaBqB-k_35_42': (209, 2048)\n",
      "Extracted features for sequence 'sPegLaBqB-k_47_53': (179, 2048)\n",
      "Extracted features for sequence 'sPegLaBqB-k_64_77': (388, 2048)\n",
      "Extracted features for sequence 'sTHXIzHPyqE_16_23': (174, 2048)\n",
      "Extracted features for sequence 'sTHXIzHPyqE_24_29': (124, 2048)\n",
      "Extracted features for sequence 'Su1YLAjty-U_274_281': (209, 2048)\n",
      "Extracted features for sequence 'sZdRTEjdbmw_209_224': (448, 2048)\n",
      "Extracted features for sequence 'T2h6Yvxf8CA_126_133': (208, 2048)\n",
      "Extracted features for sequence 'T2h6Yvxf8CA_597_605': (238, 2048)\n",
      "Extracted features for sequence 'T6dCYE56etM_0_19': (473, 2048)\n",
      "Extracted features for sequence 'T6dCYE56etM_20_32': (299, 2048)\n",
      "Extracted features for sequence 'T6dCYE56etM_35_47': (299, 2048)\n",
      "Extracted features for sequence 'TJXzIX8tl2M_36_41': (125, 2048)\n",
      "Extracted features for sequence 'tnthhVYcH3I_220_229': (215, 2048)\n",
      "Extracted features for sequence 'Twfy_jWEDt4_108_117': (215, 2048)\n",
      "Extracted features for sequence 'Twfy_jWEDt4_135_142': (167, 2048)\n",
      "Extracted features for sequence 'Twfy_jWEDt4_188_194': (143, 2048)\n",
      "Extracted features for sequence 'Twfy_jWEDt4_213_219': (143, 2048)\n",
      "Extracted features for sequence 'Twfy_jWEDt4_40_46': (144, 2048)\n",
      "Extracted features for sequence 'Twfy_jWEDt4_88_94': (143, 2048)\n",
      "Extracted features for sequence 'uA8BBbJPJO0_19_25': (179, 2048)\n",
      "Extracted features for sequence 'uGm4ZFFaLK8_233_241': (239, 2048)\n",
      "Extracted features for sequence 'uGm4ZFFaLK8_96_107': (328, 2048)\n",
      "Extracted features for sequence 'UhDgpXWkFHE_279_286': (208, 2048)\n",
      "Extracted features for sequence 'Upu96iQH_d0_196_213': (424, 2048)\n",
      "Extracted features for sequence 'UQZxgJBLVGg_62_68': (178, 2048)\n",
      "Extracted features for sequence 'uT8kWHek_ZE_186_199': (311, 2048)\n",
      "Extracted features for sequence 'uT8kWHek_ZE_473_479': (143, 2048)\n",
      "Extracted features for sequence 'Vsgw5kzcKT0_209_220': (329, 2048)\n",
      "Extracted features for sequence 'Vsgw5kzcKT0_373_380': (209, 2048)\n",
      "Extracted features for sequence 'VsO9J5KtrR4_109_122': (324, 2048)\n",
      "Extracted features for sequence 'vuPLV3EXpjs_5_17': (299, 2048)\n",
      "Extracted features for sequence 'Vxzjzq5I-A4_71_80': (224, 2048)\n",
      "Extracted features for sequence 'Vxzjzq5I-A4_81_90': (224, 2048)\n",
      "Extracted features for sequence 'Vxzjzq5I-A4_91_97': (149, 2048)\n",
      "Extracted features for sequence 'WaU-9lwKdJs_164_169': (124, 2048)\n",
      "Extracted features for sequence 'WaU-9lwKdJs_262_272': (249, 2048)\n",
      "Extracted features for sequence 'WAUYbr5YE2U_0_13': (389, 2048)\n",
      "Extracted features for sequence 'WIgXBvSuqjI_206_212': (179, 2048)\n",
      "Extracted features for sequence 'WIgXBvSuqjI_27_32': (149, 2048)\n",
      "Extracted features for sequence 'WIgXBvSuqjI_91_96': (149, 2048)\n",
      "Extracted features for sequence 'wJChGIeWsEM_220_229': (269, 2048)\n",
      "Extracted features for sequence 'WKbN-iY7DSU_27_34': (174, 2048)\n",
      "Extracted features for sequence 'WKbN-iY7DSU_42_53': (275, 2048)\n",
      "Extracted features for sequence 'WKyaBl0EJec_505_514': (268, 2048)\n",
      "Extracted features for sequence 'wt9UHXJ1kRU_0_15': (448, 2048)\n",
      "Extracted features for sequence 'wYtP1cqH7yE_72_77': (150, 2048)\n",
      "Extracted features for sequence 'xDimkgrk6Yc_16_24': (239, 2048)\n",
      "Extracted features for sequence 'XKWYzv19pFY_85_93': (199, 2048)\n",
      "Extracted features for sequence 'xnHDu-oW7_Y_871_879': (238, 2048)\n",
      "Extracted features for sequence 'xsGabFKUhoY_122_132': (248, 2048)\n",
      "Extracted features for sequence 'XU9ii-Wygnk_0_11': (262, 2048)\n",
      "Extracted features for sequence 'xUkZPp9wqss_16_22': (149, 2048)\n",
      "Extracted features for sequence 'y13F8SXvLP0_215_222': (174, 2048)\n",
      "Extracted features for sequence 'y3TEkacYXUk_44_56': (287, 2048)\n",
      "Extracted features for sequence 'y4o7kpqrPHA_137_143': (143, 2048)\n",
      "Extracted features for sequence 'Y5mFh6F3a5I_100_114': (348, 2048)\n",
      "Extracted features for sequence 'Y5mFh6F3a5I_246_259': (323, 2048)\n",
      "Extracted features for sequence 'yATq9ymZSHM_59_73': (335, 2048)\n",
      "Extracted features for sequence 'yBJ2C6Vxxvs_158_166': (199, 2048)\n",
      "Extracted features for sequence 'yFHjS6vuFI0_26_40': (335, 2048)\n",
      "Extracted features for sequence 'yIG-xMnQUWg_69_81': (299, 2048)\n",
      "Extracted features for sequence 'yIG-xMnQUWg_85_92': (174, 2048)\n",
      "Extracted features for sequence 'Yms0Ui-dfx4_26_42': (399, 2048)\n",
      "Extracted features for sequence 'Yqv00bt7BNU_180_192': (299, 2048)\n",
      "Extracted features for sequence 'Yqv00bt7BNU_75_82': (174, 2048)\n",
      "Extracted features for sequence 'YXnHCoKw_sg_44_51': (174, 2048)\n",
      "Extracted features for sequence 'z7IlQuOqjp4_0_14': (418, 2048)\n",
      "Extracted features for sequence 'z7IlQuOqjp4_111_124': (389, 2048)\n",
      "Extracted features for sequence 'z7IlQuOqjp4_135_147': (359, 2048)\n",
      "Extracted features for sequence 'z7IlQuOqjp4_62_79': (508, 2048)\n",
      "Extracted features for sequence 'z9W_KanUqjs_114_127': (324, 2048)\n",
      "Extracted features for sequence 'z9W_KanUqjs_16_28': (299, 2048)\n",
      "Extracted features for sequence 'z9W_KanUqjs_222_231': (225, 2048)\n",
      "Extracted features for sequence 'zc4j796JGWU_112_123': (328, 2048)\n",
      "Extracted features for sequence 'ZfAykylM3Bo_281_290': (269, 2048)\n",
      "Extracted features for sequence 'ZKpVxaBOBm0_0_15': (448, 2048)\n",
      "Extracted features for sequence 'ZVdkjBoZiEA_105_114': (224, 2048)\n",
      "Extracted features for sequence 'ZVdkjBoZiEA_133_140': (174, 2048)\n",
      "Extracted features for sequence 'ZVdkjBoZiEA_76_89': (324, 2048)\n",
      "Extracted features for sequence 'ZZMOjSFMwls_71_77': (149, 2048)\n",
      "Extracted features for sequence '_9_e81xxHlA_94_102': (199, 2048)\n",
      "Extracted features for sequence '_F5SH2qQsv8_312_322': (299, 2048)\n",
      "Extracted features for sequence '_jKihXROX0E_81_92': (329, 2048)\n",
      "Extracted features for sequence '_ROpbCd4SRY_79_86': (174, 2048)\n",
      "Extracted features for sequence '_SKiA0TM-Xw_202_211': (224, 2048)\n",
      "Extracted features for sequence '_Z6E2BumgQc_223_240': (232, 2048)\n",
      "All sequences have been processed.\n"
     ]
    }
   ],
   "source": [
    "# Define the ResNet model for feature extraction\n",
    "def create_resnet_model():\n",
    "    model = resnet50(pretrained=True)\n",
    "    model = nn.Sequential(*(list(model.children())[:-1]))\n",
    "    model.eval()\n",
    "    return model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Function to preprocess frames and extract features\n",
    "def extract_features_from_frames(frames, model):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    features = []\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for frame in frames:\n",
    "            input_tensor = transform(frame).unsqueeze(0).to(device)\n",
    "            feature = model(input_tensor).squeeze().cpu().numpy()\n",
    "            features.append(feature)\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "# Initialize the CNN model\n",
    "cnn_model = create_resnet_model()\n",
    "\n",
    "# Function to process a sequence\n",
    "def process_sequence(sequence_name):\n",
    "    individual_h5_file = os.path.join(TRAIN_INDIVIDUAL_H5_DIR, f\"{sequence_name}.h5\")\n",
    "    \n",
    "    if not os.path.exists(individual_h5_file):\n",
    "        print(f\"Error: Individual HDF5 file for '{sequence_name}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    with h5py.File(individual_h5_file, 'r') as h5_individual:\n",
    "        frames = h5_individual[sequence_name]['frames'][:]\n",
    "        \n",
    "        # Load detections from det_rcnn.txt\n",
    "        det_rcnn_path = os.path.join(TRAIN_PATH, sequence_name, \"det\", \"det_rcnn.txt\")\n",
    "        detections = []\n",
    "\n",
    "        if os.path.exists(det_rcnn_path):\n",
    "            with open(det_rcnn_path, 'r') as f:\n",
    "                det_data = f.readlines()\n",
    "                for line in det_data:\n",
    "                    parts = line.strip().split(',')\n",
    "                    if len(parts) >= 7:\n",
    "                        detections.append({\n",
    "                            \"frame_number\": int(float(parts[0])),  # Convert to float first then to int\n",
    "                            \"class_id\": int(float(parts[1])),      # Convert to float first then to int\n",
    "                            \"score\": float(parts[2]),\n",
    "                            \"bbox\": [float(part) for part in parts[3:7]]\n",
    "                        })\n",
    "\n",
    "        # Extract features from frames using the CNN model\n",
    "        train_features = extract_features_from_frames(frames, cnn_model)\n",
    "        \n",
    "        # Save features in the specified directory\n",
    "        np.save(os.path.join(FEATURES_DIR, f\"{sequence_name}_features.npy\"), train_features)\n",
    "        print(f\"Extracted features for sequence '{sequence_name}': {train_features.shape}\")\n",
    "\n",
    "        # Clear memory after processing each sequence\n",
    "        del frames\n",
    "        del detections\n",
    "        gc.collect()  # Force garbage collection\n",
    "\n",
    "# Process each sequence in the training set\n",
    "for dir_name in os.listdir(TRAIN_PATH):\n",
    "    sequence_name = os.path.basename(dir_name)\n",
    "    process_sequence(sequence_name)\n",
    "\n",
    "print(\"All sequences have been processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5d5d33",
   "metadata": {},
   "source": [
    "# 4. LSTM Model Definition\n",
    "This defines the LSTM model that will take the CNNs output features as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25df8b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Shape before conversion: (0,)\n",
      "Train Features Shape after conversion: torch.Size([1, 1, 0])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 2048, got 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 76\u001b[0m\n\u001b[0;32m     73\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels_tensor)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcontiguous()  \u001b[38;5;66;03m# Ensure the input tensor is contiguous\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msigmoid(out)\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:913\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    910\u001b[0m             hx \u001b[38;5;241m=\u001b[39m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    912\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m--> 913\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    914\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:827\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    823\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m    824\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[0;32m    825\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[0;32m    826\u001b[0m                        ):\n\u001b[1;32m--> 827\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    829\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    830\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    831\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:246\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    247\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 2048, got 0"
     ]
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        x = x.contiguous()  # Ensure the input tensor is contiguous\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "# Initialize the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize LSTM model\n",
    "input_size = 2048  # ResNet-50 feature size\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "lstm_model = LSTMModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "# Training setup\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Load extracted features and labels\n",
    "train_features = []\n",
    "train_labels = []\n",
    "\n",
    "for dir_name in os.listdir(TRAIN_PATH):\n",
    "    sequence_name = os.path.basename(dir_name)\n",
    "    feature_path = os.path.join(FEATURES_DIR, f\"{sequence_name}_features.npy\")\n",
    "    label_path = os.path.join(TRAIN_PATH, sequence_name, \"gt\", \"labels.npy\")  # Assuming labels are saved as NumPy arrays\n",
    "\n",
    "    if os.path.exists(feature_path) and os.path.exists(label_path):\n",
    "        features = np.load(feature_path)\n",
    "        labels = np.load(label_path)\n",
    "        \n",
    "        train_features.append(features)\n",
    "        train_labels.append(labels)\n",
    "\n",
    "# Convert lists to tensors properly\n",
    "train_features_np = np.array(train_features, dtype=np.float32)  # Convert list to NumPy array first\n",
    "train_labels_np = np.array(train_labels, dtype=np.float32)\n",
    "\n",
    "# Check the shape of train_features_np before conversion\n",
    "print(f\"Shape before conversion: {train_features_np.shape}\")  # Debugging\n",
    "\n",
    "# Ensure it's at least 3D (batch_size, seq_len, input_size)\n",
    "if train_features_np.ndim == 2:  # (batch_size, input_size)\n",
    "    train_features_np = np.expand_dims(train_features_np, axis=1)  # Add sequence dimension\n",
    "elif train_features_np.ndim == 1:  # (input_size)\n",
    "    train_features_np = np.expand_dims(train_features_np, axis=0)  # Add batch dimension\n",
    "    train_features_np = np.expand_dims(train_features_np, axis=1)  # Add sequence dimension\n",
    "\n",
    "train_features_tensor = torch.tensor(train_features_np).to(device)\n",
    "labels_tensor = torch.tensor(train_labels_np).float().unsqueeze(1).to(device)  # Ensure (batch_size, 1)\n",
    "\n",
    "print(f\"Train Features Shape after conversion: {train_features_tensor.shape}\")  # Debugging\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    lstm_model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = lstm_model(train_features_tensor)\n",
    "    loss = criterion(outputs, labels_tensor)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "# Real-time tracking function\n",
    "def run_real_time_tracking(model, cnn_model):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to read frame from webcam.\")\n",
    "            break\n",
    "\n",
    "        frame_resized = cv2.resize(frame, (224, 224))\n",
    "        frame_tensor = torch.tensor(frame_resized, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "        frame_tensor = frame_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = cnn_model(frame_tensor)\n",
    "            features = features.unsqueeze(1)  # Add time dimension\n",
    "            features = features.contiguous()  # Ensure the tensor is contiguous\n",
    "            prediction = model(features)  # Forward pass through FC model\n",
    "\n",
    "        label = \"Person\" if prediction.item() > 0.5 else \"No Person\"\n",
    "        cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Real-Time Tracking\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the tracking function\n",
    "run_real_time_tracking(lstm_model, cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57be386c",
   "metadata": {},
   "source": [
    "# 5. Training with Checkpoints\n",
    "Include checkpoints to save the best-performing model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12842d7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Zero the gradients\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels_tensor\u001b[38;5;241m.\u001b[39mto(device))  \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[38], line 15\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 15\u001b[0m     x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass through first LSTM\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)    \u001b[38;5;66;03m# Apply dropout\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm2(x)   \u001b[38;5;66;03m# Pass through second LSTM\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:917\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    914\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 917\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    920\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    921\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input."
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    lstm_model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = lstm_model(train_features_tensor.to(device))\n",
    "    loss = criterion(outputs, labels_tensor.to(device))\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573fcfc4",
   "metadata": {},
   "source": [
    "# 6. Evaluation and Metrics\n",
    "Calculate the IoU and MOTA metrics for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d76feb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU: 0.47\n"
     ]
    }
   ],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    xA = max(box1[0], box2[0])\n",
    "    yA = max(box1[1], box2[1])\n",
    "    xB = min(box1[2], box2[2])\n",
    "    yB = min(box1[3], box2[3])\n",
    "\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    box1Area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2Area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    \n",
    "    return interArea / float(box1Area + box2Area - interArea)\n",
    "\n",
    "# Example usage\n",
    "iou = calculate_iou([50, 50, 100, 100], [60, 60, 110, 110])\n",
    "print(f\"IoU: {iou:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce56336",
   "metadata": {},
   "source": [
    "# 7. Real-Time Tracking with Webcam/Video Input\n",
    "This part enables real-time tracking using your webcam or video input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17e0c65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x128 and 2048x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 81\u001b[0m\n\u001b[0;32m     78\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Run the tracking function\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m \u001b[43mrun_real_time_tracking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfully_connected_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnn_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[47], line 68\u001b[0m, in \u001b[0;36mrun_real_time_tracking\u001b[1;34m(model, cnn_model)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     67\u001b[0m     features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Add time dimension\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Forward pass through FC model\u001b[39;00m\n\u001b[0;32m     70\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerson\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prediction\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo Person\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(frame, label, (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m30\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[47], line 25\u001b[0m, in \u001b[0;36mFullyConnectedModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 25\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m     27\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Joshua Menezes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x128 and 2048x128)"
     ]
    }
   ],
   "source": [
    "def run_real_time_tracking(model, cnn_model):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to read frame from webcam.\")\n",
    "            break\n",
    "\n",
    "        frame_resized = cv2.resize(frame, (224, 224))\n",
    "        frame_tensor = torch.tensor(frame_resized, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "        frame_tensor = frame_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = cnn_model(frame_tensor)\n",
    "            features = features.unsqueeze(1)\n",
    "            prediction = model(features)\n",
    "\n",
    "        label = \"Person\" if prediction.item() > 0.5 else \"No Person\"\n",
    "        cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Real-Time Tracking\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the tracking function\n",
    "run_real_time_tracking(lstm_model, cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b06e2f9",
   "metadata": {},
   "source": [
    "# 8. Save and Load Model\n",
    "This part ensures that you save and reload your trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(lstm_model.state_dict(), \"lstm_tracking_model.pth\")\n",
    "\n",
    "# Load model for future use\n",
    "# lstm_model.load_state_dict(torch.load(\"lstm_tracking_model.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
